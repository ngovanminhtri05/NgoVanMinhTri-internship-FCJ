[{"uri":"https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.1-blog1/","title":"Đại học California Irvine Sao lưu Petabyte Dữ liệu Nghiên cứu lên AWS","tags":[],"description":"","content":"Đại học California Irvine Sao lưu Petabyte Dữ liệu Nghiên cứu lên AWS Bởi Philip Papadopoulos, Abhijeet Lokhande, Evan Wood, Francisco Ramon Lopez, và Nicholas Santucci | 29 THÁNG 5 NĂM 2025\nDanh mục: Amazon Athena, Amazon CloudWatch, Amazon DynamoDB, Amazon EventBridge, Amazon S3 Glacier Deep Archive, Amazon Simple Notification Service (SNS), Amazon Simple Storage Service (S3), AWS Lambda\nGhi chú của Biên tập viên AWS không chịu trách nhiệm về kho lưu trữ GitHub công cộng của UCI được liên kết trong bài đăng này, được cung cấp để các bên quan tâm có thể khám phá giải pháp được mô tả trong bài đăng này chi tiết hơn.\nĐại học California, Irvine (UCI) là một trường đại học nghiên cứu công lập có rất nhiều dữ liệu nghiên cứu được lưu trữ trên máy chủ trong môi trường lab trên khoảng 1500 môi trường lab-nghiên cứu của giáo sư trên khuôn viên. UCI cần một giải pháp để giải quyết thách thức thực tế và kinh tế của việc cung cấp sao lưu tập trung cho các máy chủ được quản lý độc lập này.\nMục tiêu của Trung tâm Cơ sở hạ tầng Siber Nghiên cứu UCI (RCIC) là cung cấp các công cụ và dung lượng lưu trữ sao lưu mà chủ sở hữu máy chủ cần để thực hiện sao lưu đồng thời cung cấp bảo vệ dữ liệu tốt hơn trong trường hợp xóa, cố ý hay vô tình. Trung tâm RCIC của UCI đã khảo sát các giải pháp sao lưu hiện có được triển khai độc lập xung quanh khuôn viên và không tìm thấy giải pháp nào đáp ứng các yêu cầu chi phí, phạm vi quy mô động và thích ứng với thực tế của quản trị hệ thống tập trung chứ không phải phân tán. Các hệ thống ngoài lề hiện có có thể có tới Petabyte trên một máy chủ duy nhất và hơn một tỷ tệp. UCI có khoảng 100 máy chủ có dung lượng lưu trữ ước tính tổng cộng là 10 PB cần được sao lưu.\nTrong bài đăng này, chúng tôi hướng dẫn bạn qua các lựa chọn thiết kế cho giải pháp sao lưu tập trung của UCI, bao gồm cách các nhóm S3, vai trò AWS Identity and Access Management (IAM) và tài khoản AWS được tạo theo chương trình cho mỗi máy chủ để cung cấp sự cách ly thích hợp. Chúng tôi cũng sẽ cung cấp tổng quan về cách các yêu cầu cụ thể được ánh xạ tới các dịch vụ AWS và lệnh gọi rclone. Với giải pháp này, UCI đã có thể sao lưu hơn 5 PB dữ liệu (hơn 250 triệu tệp) với một hệ thống hiệu quả, có thể mở rộng được với lượng mã nhỏ gọn và dễ bảo trì.\nTổng quan Giải pháp Trung tâm RCIC của UCI đã phát triển một giải pháp sao lưu có thể mở rộng để đáp ứng các nhu cầu đa dạng của 1500 phòng lab nghiên cứu của giáo sư trên khuôn viên. Khung thực hiện tập trung vào một hệ thống được phát triển tùy chỉnh sử dụng rclone để di chuyển dữ liệu trong khi kết hợp nhiều dịch vụ AWS để bảo mật và quản lý dữ liệu. Giải pháp này được thiết kế đặc biệt để xử lý sự khác biệt lớn trong kích thước máy chủ trên khuôn viên, từ 1 TB đến 2 PB, với yêu cầu lưu trữ tổng cộng khoảng 10 PB trên 100 máy chủ.\nKiến trúc thực hiện thiết lập ranh giới rõ ràng giữa vai trò quản lý hệ thống và quản lý đám mây, tăng cường bảo mật thông qua tách biệt nhiệm vụ. Các máy chủ tại chỗ (Lab1 và LabN) sử dụng rclone để thực hiện sao lưu hàng ngày tới các nhóm S3. Các nhóm S3 được định cấu hình với các chính sách Vòng đời S3 di chuyển dữ liệu tới S3 Glacier Deep Archive để lưu trữ dài hạn. Hệ thống được giám sát bằng Amazon CloudWatch với bảng điều khiển tùy chỉnh và cảnh báo, trong khi thông báo được xử lý thông qua Amazon Simple Notification Service (Amazon SNS). Các dịch vụ AWS bổ sung và tính năng như Amazon DynamoDB, AWS Lambda, AWS Step Functions, S3 Batch Operations và Amazon EventBridge được sử dụng để kiểm soát quyền truy cập và mô tả chính sách.\nSơ đồ Kiến trúc Hình 1: Khung nhìn cấp cao về sao lưu tới Amazon S3 bằng rclone. Một loạt các dịch vụ AWS được sử dụng để kiểm soát quyền truy cập và mô tả chính sách. Một trình bao quanh Python3 tùy chỉnh xung quanh công cụ rclone mã nguồn mở hợp lý hóa mô tả các công việc sao lưu.\nCác Thành phần Chính Để duy trì hiệu quả chi phí đồng thời đảm bảo bảo vệ dữ liệu, Trung tâm RCIC của UCI đã phát triển một trình bao quanh Python tùy chỉnh hợp lý hóa các định nghĩa công việc sao lưu và thực hiện. Trình bao quanh này giao diện với các dịch vụ AWS bao gồm S3, IAM, Amazon CloudWatch và Amazon SNS để cung cấp khả năng giám sát và quản lý toàn diện.\nHình 2: Một trình bao quanh Python tùy chỉnh xung quanh công cụ rclone mã nguồn mở hợp lý hóa mô tả các công việc sao lưu\nGiải pháp kết hợp ba thành phần hoạt động chính:\nSao lưu tăng hàng ngày để bảo vệ dữ liệu hiệu quả Đồng bộ sâu hàng tuần để xác minh toàn diện Quản lý vòng đời tự động để tối ưu hóa chi phí Việc triển khai cách tiếp cận phân tầng này cho phép UCI cân bằng thành công các yêu cầu cạnh tranh về hiệu suất, chi phí và bảo mật dữ liệu trong khi duy trì khả năng sẵn có của hệ thống cho các hoạt động nghiên cứu.\nMa trận Thực hiện Tính năng Tính năng/Khả năng Công nghệ/Dịch vụ Kiểm soát Di chuyển dữ liệu/sao lưu rclone sysadmin Định nghĩa công việc sao lưu Tệp yaml tùy chỉnh sysadmin Thực hiện công việc sao lưu Mã được phát triển bởi UCI bao quanh rclone sysadmin (trên GitHub) Lập lịch công việc sao lưu Unix Cron, Windows Scheduled tasks sysadmin Xóa tệp trên sao lưu rclone chạy ở chế độ đồng bộ sysadmin Bảo vệ ghi đè/xóa tệp S3 Versioning cloudadmin Xóa vĩnh viễn bản sao lưu Chính sách Vòng đời S3 cloudadmin Xóa sớm dữ liệu S3 Admin – Yêu cầu MFA cloudadmin Cung cấp đích sao lưu Tập lệnh tùy chỉnh nhắm mục tiêu S3 và áp dụng chính sách cloudadmin Hạn chế mạng IP Chính sách quyền truy cập IAM cloudadmin Tổng quan và chế độ xem từng máy chủ Bảng điều khiển Cloudwatch cloudadmin Hạn ngạch và cảnh báo hoạt động Cảnh báo Cloudwatch cloudadmin Khôi phục tệp S3 Glacier restore + python tùy chỉnh cloudadmin/sysadmin Phương pháp Sao lưu Tập trung A. Di chuyển Dữ liệu Cơ bản Tại sao chọn rclone? Rclone cung cấp hỗ trợ cho cả lưu trữ Amazon S3 và hệ thống tệp cục bộ, với xử lý tích hợp của versioning đối tượng S3 và tích hợp trực tiếp với các API lưu trữ đám mây. Công cụ này sử dụng phương pháp khám phá hệ thống tệp tăng dần, cho phép xử lý hiệu quả bộ nhớ của các hệ thống tệp lớn, được xác minh với các hệ thống chứa hơn 50 triệu tệp. Khi rclone cần đồng bộ hóa nội dung của hệ thống tệp cục bộ với bản sao trong Amazon S3, nó khám phá hệ thống tệp cục bộ theo cách tăng dần. UCI có các công việc sao lưu duy nhất với hơn 50 triệu tệp và rclone hoàn toàn khám phá hệ thống tệp mà không làm cạn kiệt bộ nhớ hệ thống.\nRclone cũng có đa luồng natively. Ví dụ, khi thực hiện \u0026ldquo;đầy đủ\u0026rdquo; sao lưu đầu tiên của máy chủ tệp 1 PB, UCI đã \u0026ldquo;giảm lại\u0026rdquo; rclone để nó không làm bão hòa liên kết 10 GbE và máy chủ tệp vẫn có khả năng phục vụ tệp. Tóm lại, nó có hiệu suất nhưng có thể được quản lý để nó không làm hệ thống không khả dụng.\nUCI đã phát triển một tập lệnh Python nhỏ (gen-backup.py trong kho lưu trữ GitHub công cộng của UCI) bao quanh Rclone. Mã này diễn giải một tệp được định dạng YAML xác định một hoặc nhiều công việc sao lưu.\nVí dụ Định nghĩa Công việc Sao lưu ## Đường dẫn là thông thường cho các công việc liên quan đến đường dẫn --- srcpaths: - path: /datadir ## Quyết định cục bộ loại trừ thư mục con .git exclude_global: - .git/** ## Mẫu từ một tệp để loại trừ exclude_file: common_excludes.yaml jobs: - name: backup1 subdirectories: - DataImages Nói tóm lại, công việc có tên \u0026ldquo;backup1\u0026rdquo; sao chép tất cả các tệp trong đường dẫn /datadir/DataImages và loại trừ các mẫu tệp thông thường. Để chạy tất cả các công việc sao lưu, chỉ cần phát hành lệnh sau:\ngen-backup.py run Có rất nhiều tùy chọn cho gen-backup để quản lý tính song song, công việc nào được chạy và ở chế độ nào chúng được chạy.\nCác Bước Thực hiện Chuyển dữ liệu Cấu hình: UCI đã cấu hình các hồ sơ sao lưu riêng lẻ cho mỗi máy chủ lab nghiên cứu Định nghĩa công việc: Tạo các mẫu YAML được chuẩn hóa để định nghĩa sao lưu nhất quán Thực hiện: Triển khai các quy trình sao lưu tự động thông qua trình bao quanh tùy chỉnh Giám sát: Thiết lập các giao thức giám sát dành riêng cho lab Tối ưu hóa: Phát triển các điều khiển tốc độ truyền dựa trên dung lượng máy chủ Lập lịch: Tạo các lịch biểu sao lưu dành riêng cho lab dựa trên tỷ lệ thay đổi dữ liệu Phương pháp có cấu trúc này đảm bảo các hoạt động sao lưu nhất quán, có thể tái tạo được trong khi duy trì hiệu suất và độ tin cậy của hệ thống trong các tham số hoạt động được xác định.\nB. Hạn ngạch Lưu trữ cho Lab Đội IT trung tâm của khuôn viên quản lý chi phí sao lưu, đòi hỏi thực hiện các điều khiển cụ thể để ngăn chặn vượt quá chi phí. Để đạt được điều này, các yếu tố sau cần được hiểu cho mỗi máy chủ:\nCó bao nhiêu dữ liệu về khối lượng (tính bằng terabyte) được lưu trữ? Có bao nhiêu tệp trong hệ thống (tính bằng gia tăng 1 triệu đối tượng)? Liệu quyền truy cập vào nhóm S3 sao lưu có vẻ \u0026ldquo;lạm dụng\u0026rdquo; (quá nhiều giao dịch)? Một hệ thống đã không thực hiện bất kỳ lệnh gọi API nào tới nhóm (sao lưu có thể bị tắt trên máy chủ)? Mỗi một trong các gạch đầu dòng này được cấu hình dưới dạng cảnh báo CloudWatch. Cả cloudadmin và sysadmin (các) phù hợp được thông báo bất cứ khi nào bất kỳ cảnh báo nào trong số này được kích hoạt bằng Amazon SNS. Có một bảng điều khiển cho phép cloudadmins xem trạng thái của các cảnh báo này cho tất cả các máy chủ đang được sao lưu.\nHình 4: Cảnh báo được thiết lập cho mỗi máy chủ lưu trữ: giám sát hạn ngạch lưu trữ và đối tượng cũng như hoạt động\nMột cảnh báo như vậy theo dõi các lệnh gọi API, được biểu thị dưới dạng tỷ lệ của yêu cầu tới các đối tượng. Nếu tỷ lệ này vượt quá 3,5, cảnh báo sẽ được kích hoạt. 3,5 được chọn làm đệm kỹ thuật để không báo động trong hầu hết các tình huống hoạt động.\nTrong thời gian gần một năm, các cảnh báo này đã chứng minh hữu ích để báo động UCI về các trạng thái khác nhau - đặc biệt là trên các giới hạn terabyte và số lượng đối tượng.\nC. Giám sát và Tính Chất Hiển thị Hệ thống giám sát cần phải thích ứng với 50-100 máy chủ hoạt động theo lịch biểu sao lưu độc lập. Với các hệ thống cuối được quản lý bởi các quản trị viên khác nhau và không có liên kết, chỉ có dữ liệu trong AWS có thể được sử dụng làm điểm tập hợp trung tâm. Để kiểm soát chi phí, UCI quan tâm nhất đến các mức trung bình. Một số máy chủ có thể có nhiều tệp nhỏ hoặc thay đổi dữ liệu đáng kể (dẫn đến tỷ lệ phần trăm cao hơn các đối tượng không hiện tại) và do đó \u0026ldquo;đắt hơn mỗi terabyte\u0026rdquo;. Những tệp này được cân bằng bởi các máy chủ khác có các tệp tương đối lớn và/hoặc thay đổi dữ liệu thấp và do đó \u0026ldquo;rẻ hơn mỗi terabyte\u0026rdquo;.\nUCI đã xây dựng một bảng điều khiển tùy chỉnh trong CloudWatch kết hợp các số liệu từ tất cả các nhóm sao lưu, tách biệt các lệnh gọi API khác nhau để ước tính chi phí liên tục. Tiện ích hàng đầu hiển thị tổng dung lượng lưu trữ 2780 TB trên 186 triệu tệp. Trong tổng dung lượng lưu trữ này là 2690 TB trong S3 Glacier Deep Archive và 454 TB được giữ dưới dạng tệp đã xóa hoặc ghi đè mà chưa được xóa vĩnh viễn thông qua chính sách Vòng đời S3. Hình cuối cùng cho biết chi phí chung là 16,3% để giữ lại các đối tượng đã xóa/thay đổi.\nHình 5: Tổng thể lưu trữ, API và sử dụng chi phí trên tất cả các máy chủ\nCác bất thường hàng tuần trên biểu đồ API đến từ việc đồng bộ sâu hàng tuần. Một kiểm tra cẩn thận cũng cho thấy tăng lên của lưu trữ tiêu chuẩn 2 TB ở đầu cửa sổ giám sát và 88,1 TB ở cuối. Điều này được giải thích bằng sự onboarding của máy chủ 1 PB mới.\nPhần chiếm ưu thế của hóa đơn sao lưu hàng tháng của UCI đến từ chi phí của chính lưu trữ, chiếm khoảng 80% chi phí hàng tháng. Phân tích hóa đơn tháng 7 năm 2024 cho thấy:\n80% lưu trữ 1,5% CloudWatch 18,5% API Chi phí bổ sung không được hiển thị có tầm quan trọng là chi phí chuyển đổi S3 Lifecycle khi dữ liệu được di chuyển từ Amazon S3 Standard (nơi nó được đặt ban đầu) tới S3 Glacier Deep Archive.\nGiám sát Per-Server Bảng điều khiển tổng quan là hữu ích, nhưng các chế độ xem cấp cao cho mỗi máy chủ cũng rất quan trọng để hiểu rõ. Bảng điều khiển ước tính chi phí thứ hai được cấu hình để có được thông tin chi tiết này. Các hệ thống tại UCI có khả năng từ 11 TB đến 1040 TB và số lượng đối tượng trong phạm vi 652.000 đến 59,4 triệu. Bảng điều khiển này sao chép thông tin dòng trên cùng của chế độ xem tổng hợp, nhưng nó được điều chỉnh cho từng hệ thống.\nHình 6: Sử dụng lưu trữ và chi phí per-server\nTất cả các bảng điều khiển hiển thị được xây dựng theo chương trình để chúng có thể được sao chép dễ dàng trong môi trường khác.\nD. Sao lưu Có Hiệu suất Khi xử lý các máy chủ dữ liệu lớn, khối lượng (terabyte) và số lượng tệp (số lượng đối tượng) là các yếu tố quan trọng ảnh hưởng đến hiệu suất. Có lẽ dễ nhất để minh họa các độ lớn này với một số ví dụ:\n1024 TB @ 1 gbps – 10 triệu giây để truyền (100 Ngày) 1024 TB @ 10 gbps – 1 triệu giây để truyền (10 ngày) Đồng bộ hóa 50 triệu tệp ở 100 checks/second = 500.000 giây (5,8 ngày) Đồng bộ hóa 50 triệu tệp ở 1000 checks/second = 50.000 giây (13,8 giờ) Để sao lưu lên đám mây thực tế trên các máy chủ 1 PB, bản sao đầu tiên của dữ liệu cần phải di chuyển với tốc độ vượt quá 1 gbps. Khi đánh giá phần mềm hiện có, rõ ràng là bất kỳ chiến lược sao lưu nào yêu cầu \u0026ldquo;đầy đủ\u0026rdquo; sao lưu thường xuyên của các loại máy chủ này là không thực tế. Mặc dù tư nhân hóa một sao lưu lớn có thể mất thời gian đáng kể (hàng tuần trong các trường hợp cực đoan) và không thể tránh khỏi, sao lưu liên tục cần phải \u0026ldquo;mãi mãi tăng dần\u0026rdquo;.\nSố liệu thứ hai (checks/sec) không quá rõ ràng thoạt đầu. Để đồng bộ hóa nội dung của hai \u0026ldquo;hệ thống\u0026rdquo; tệp, phần mềm sao lưu phải xác minh rằng mọi thứ cục bộ nằm trên bản sao lưu. Hơn nữa, mọi thứ đã bị xóa từ máy cục bộ cũng phải bị xóa từ bản sao lưu. Rclone thực hiện điều này với \u0026ldquo;những người kiểm tra\u0026rdquo; kiểm tra xem các bản sao cục bộ và đám mây có đồng bộ hóa hay không. Vì mỗi lần kiểm tra là một lệnh gọi API trên mạng có hàng chục mili giây trên mỗi lệnh gọi, nhiều kiểm tra như vậy phải xảy ra song song. Rclone làm điều này native và UCI thường xuyên quan sát khoảng 2000 checks/second.\nNgoài ra, một tổ chức có thể giữ một cơ sở dữ liệu cục bộ của trạng thái của từng tệp và giảm \u0026ldquo;đồng bộ hóa\u0026rdquo; thường xuyên. Đó là sự đánh đổi giữa không gian (một cơ sở dữ liệu cục bộ) và thời gian (đồng bộ hóa sâu hàng tuần). Nhiều chương trình sao lưu thương mại làm điều này (và phải luôn có cách thiết lập lại sự thật nếu cơ sở dữ liệu cục bộ bị hỏng). Quản lý cơ sở dữ liệu như vậy làm tăng độ phức tạp.\nE. Chi phí Thấp Tối ưu hóa chi phí là một yêu cầu chính, yêu cầu phân tích cẩn thận về sử dụng tính năng AWS để kiểm soát chi phí. UCI phải hiểu một số kiến thức cơ bản về cách rclone giao diện với Amazon S3, sau đó thực hiện phép nhân. Sau khi kiểm tra các vấn đề hiệu suất thực tế, UCI đã chọn \u0026ldquo;đồng bộ sâu\u0026rdquo; hàng tuần của các hệ thống tệp. Các đồng bộ sâu dẫn đến một số lệnh gọi API lớn và tác động đến hệ thống tệp cục bộ. Rclone có một chế độ được gọi là đồng bộ \u0026ldquo;top up\u0026rdquo;. Nó chỉ xem xét các tệp mới hoặc mới được viết để so sánh với bản sao đám mây. Các hệ thống chạy top-ups sáu ngày/tuần và một đồng bộ sâu một ngày/tuần.\nF. Xoay Mật khẩu và Phát hiện Non-Running Tập lệnh sao lưu (gen-backup.py) phải có thể chạy không được giám sát từ một bộ lập lịch nhiệm vụ (ví dụ cron trên các hệ thống giống Linux, Task Scheduler trên Windows). Để làm điều này, rclone phải có quyền truy cập vào các thông tin xác thực hợp lệ. Điều này cung cấp một phần của một đặc vụ kỹ thuật: các khóa tạm thời (dài hạn) có thể hết hạn trước khi sao lưu hoàn tất trong khi thông tin xác thực dài hạn tạo ra những rủi ro của riêng chúng. Rclone tới S3 để sao lưu lớn (RCS3) \u0026ldquo;chia giữa\u0026rdquo;: thông tin xác thực (cụ thể cho quá trình sao lưu chính nó) là dài hạn nhưng hết hạn sau khi hoàn tất mỗi lệnh gọi thành công của chương trình sao lưu (gen-backup.py). Theo hoạt động bình thường, điều này xảy ra hàng ngày.\nKhi một nhóm được thiết lập để sao lưu, một tài khoản dịch vụ (người dùng sao lưu) được tạo và tài khoản này phải có đặc quyền tạo một cặp khóa truy cập mới/khóa truy cập bí mật chỉ cho chính nó. Sự thỏa hiệp này hoạt động rất tốt. Khi rclone bắt đầu, khóa đang được sử dụng không hết hạn trong khi sao lưu đang diễn ra, do đó ngăn chặn những lần khởi động lại sao lưu không cần thiết. Khi hoàn tất, khóa vừa được sử dụng hết hạn và một khóa mới được tạo. Trong hoạt động bình thường, khóa có tuổi thọ là 24 giờ.\nMột người có thể sử dụng thực tế rằng hoạt động bình thường sẽ thấy một cập nhật khóa mỗi ngày. Điều này kích hoạt cảnh báo nếu một khóa cụ thể có tuổi hơn 48 giờ. Điều này cho biết rằng: một sao lưu mất lâu hơn hoặc một sao lưu không đi tới bước xoay khóa. Trường hợp sau là luôn luôn một vấn đề. Nguyên nhân gốc của cảnh báo đòi hỏi sysadmin phải điều tra.\nKết luận Giải pháp sao lưu toàn diện được phát triển bởi Trung tâm RCIC của UCI chứng minh cách các dịch vụ AWS có thể được tận dụng hiệu quả để giải quyết thách thức phức tạp của việc sao lưu lượng dữ liệu khổng lồ nghiên cứu trên nhiều phòng lab của giáo sư. Thông qua việc thực hiện chiến lược của rclone, các trình bao quanh Python tùy chỉnh và các dịch vụ AWS khác nhau bao gồm S3, IAM, CloudWatch và SNS, UCI đã tạo thành công một hệ thống có thể mở rộng có khả năng sao lưu hơn 5 PB dữ liệu bao gồm hơn 250 triệu tệp.\nKiến trúc giải pháp cân bằng hiệu quả các yêu cầu quan trọng bao gồm hiệu quả chi phí, tối ưu hóa hiệu suất, các điều khiển bảo mật và khả năng giám sát trong khi duy trì một ranh giới rõ ràng giữa vai trò quản lý hệ thống và quản lý đám mây.\nLợi ích Chính Tiết kiệm Chi phí: Phân tầng lưu trữ thông minh và các chính sách vòng đời Bảo mật: Tách biệt nhiệm vụ và kiểm soát quyền truy cập nghiêm ngặt Giám sát: Khả năng toàn diện với cả cái nhìn tổng quan cấp cao và chi tiết per-server Khả năng mở rộng: Xử lý các máy chủ từ 1 TB đến 2 PB trong khi duy trì hiệu suất hệ thống Đối với các tổ chức muốn thực hiện một giải pháp tương tự, cách tiếp cận của UCI chứng minh rằng với kế hoạch cẩn thận và kết hợp đúng đắn các công cụ và dịch vụ, ngay cả những yêu cầu sao lưu đòi hỏi nhất cũng có thể được đáp ứng hiệu quả.\nTài nguyên Được Khuyến nghị Kho lưu trữ GitHub công cộng của UCI Tài liệu RCS3 Tài liệu cung cấp tổng quan về hai bên quản lý của sao lưu và những gì cần thiết về phần mềm (Python, Thư viện Boto3 và rclone), khởi tạo môi trường đám mây cho sao lưu, onboarding các máy chủ, tạo các công việc sao lưu, xác định hạn ngạch và cập nhật bảng điều khiển.\nLộ trình Tương lai RCS3 đã chứng minh hiệu quả của việc quản lý các sao lưu quy mô Petabyte trong khi duy trì hiệu quả chi phí. Danh sách việc cần làm gần hạn của chúng tôi bao gồm:\nCác hoạt động khôi phục không được hỗ trợ (không có can thiệp cloudadmin) Tài liệu về các tùy chọn công việc sao lưu khác nhau có thể giải quyết các vấn đề phổ biến Chi tiết về thiết lập tất cả các biến thể hệ thống đã gặp cho đến nay Về các Tác giả Philip Papadopoulos Philip Papadopoulos là Giám đốc Trung tâm Cơ sở hạ tầng Siber Nghiên cứu (RCIC) tại Đại học California, Irvine (UCI). RCIC phục vụ cộng đồng nghiên cứu của khuôn viên thông qua một cụm máy tính quy mô trung bình (khoảng 11K lõi và 150 GPU) và khoảng 10 PB lưu trữ song song. Tiến sĩ P. bắt đầu làm việc trong cộng đồng máy tính song song/phân tán tại Phòng thí nghiệm Quốc gia Oak Ridge như là một phần của PVM (tiền thân của MPI) vào cuối những năm 1990. Trước khi đến UCI, ông đã dành gần hai mươi năm tại Trung tâm Máy tính Siêu cấp San Diego xây dựng các hệ thống máy tính siêu cấp và phát triển bộ công cụ cụm Rocks.\nAbhijeet Lokhande Abhijeet Lokhande là một Kiến trúc sư Giải pháp Cao cấp tại AWS, nơi anh ấy đóng một vai trò quan trọng trong việc trao quyền cho các công ty khởi nghiệp đổi mới nhất của Ấn Độ. Làm việc trong nhóm AWS Startups, anh ấy phục vụ như một cố vấn chiến lược, giúp các công ty mới nổi chuyển đổi các tầm nhìn tham vọng của họ thành các kiến trúc đám mây có thể mở rộng. Với chuyên môn sâu về bảo mật và tuân thủ, Abhijeet hướng dẫn các nhà sáng lập thông qua sự phức tạp của việc xây dựng các ứng dụng cấp doanh nghiệp an toàn trên AWS.\nEvan Wood Evan là một Kiến trúc sư Giải pháp làm việc với nhóm Amazon Web Services (AWS) Công lập Toàn cầu. Anh ấy làm việc với Bộ Năng lượng trong không gian Dân sự Liên bang, giúp họ tăng tốc Hành trình đám mây của họ. Evan chuyên về triển khai IoT và cơ sở dữ liệu.\nFrancisco Ramon Lopez Francisco là một chuyên gia CNTT làm việc trong Trung tâm Cơ sở hạ tầng Siber Nghiên cứu (RCIC) tại Đại học California, Irvine. Anh ấy có hơn 25 năm kinh nghiệm với các hệ thống UNIX và bắt đầu làm việc với AWS vào năm 2015.\nNicholas Santucci Nick Santucci là một Kỹ sư Hệ thống Máy tính Hiệu suất Cao tại Trung tâm Cơ sở hạ tầng Siber Nghiên cứu (RCIC) của UC Irvine, thuộc phòng Công nghệ Dữ liệu và Thông tin (ODIT). Anh ấy chuyên về tích hợp phần mềm, máy tính cụm và lưu trữ hiệu suất cao, hỗ trợ sứ mệnh của RCIC cung cấp các tài nguyên máy tính và lưu trữ có thể mở rộng cho cộng đồng nghiên cứu của khuôn viên. Trước khi tham gia UC Irvine để làm việc trong máy tính hiệu suất cao/máy tính nghiên cứu, anh ấy đã dành một thập kỷ tại DIRECTV, nơi anh ấy phát triển và di chuyển các hệ thống giám sát tự động cho các hoạt động phát sóng, dịch chuyển thực hành từ giám sát dựa trên công cụ sang phân tích IT dựa trên dữ liệu. Nick có bằng cấp về thạc sĩ về khoa học thông tin và máy tính từ UC Irvine, có chuyên môn về mạng và hệ thống phân tán.\nTags: Amazon Athena, Amazon CloudWatch, Amazon DynamoDB, Amazon EventBridge, Amazon S3 Batch Operations, Amazon S3 Glacier Storage Classes, Amazon Simple Storage Service (Amazon S3), Amazon SNS, AWS Cloud Storage, AWS Lambda\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Ngô Văn Minh Trí\nSố điện thoại: 0965420205\nEmail: ngovanminhtri05@gmail.com\nTrường: Đại học FPT chi nhánh HCM\nNgành: Kỹ thuật phần mềm\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong trang này bạn sẽ cần giới thiệu worklog của bạn như thế nào? Bạn hoàn thành chương trình trong vòng bao nhiêu tuần? Bạn đã làm gì trong các tuần đó?\nThông thường và cũng là tiêu chuẩn, một worklog được thực hiện trong khoảng 3 tháng (trong suốt thời gian thực tập) với nội dung các tuần như sau:\nTuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS\nTuần 2: AWS Foundations và Command Line Mastery\nTuần 3: Thiết kế VPC \u0026amp; Secure Compute\nTuần 4: Managed Databases \u0026amp; Storage\nTuần 5: High Availability \u0026amp; Auto Scaling\nTuần 6: Monitoring \u0026amp; Observability\nTuần 7: Content Delivery \u0026amp; Edge Security\nTuần 8: Ôn tập kiến thức cho bài kiểm tra giữa kỳ\nTuần 9: Khởi động dự án - Smart Office IoT Core\nTuần 10: Smart Office - Rules Engine \u0026amp; Data Persistence\nTuần 11: Smart Office - Serverless API \u0026amp; Visualization\nTuần 12: Hoàn thiện và trình bày dự án cuối cùng\nTuần 13: Chứng chỉ AWS trên Coursera\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 1: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 1: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 2: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 2: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.4-week4/","title":"Worklog Tuần 4: Cơ sở dữ liệu (Database) &amp; Lưu trữ (Storage)","tags":[],"description":"","content":" ⚠️ Lưu ý: Thông tin dưới đây chỉ mang tính chất tham khảo. Vui lòng không sao chép nguyên văn cho báo cáo của bạn.\n[Hình ảnh sơ đồ kiến trúc 2-tier với EC2 trong Public Subnet và RDS trong Private Subnet]\nMục tiêu Tuần 4: Làm chủ Managed Services (Dịch vụ được quản lý): Hiểu rõ lợi ích vận hành khi sử dụng Amazon RDS so với việc tự cài đặt database trên EC2. Triển khai Kiến trúc 2-Tier: Kết nối an toàn giữa Web Server (EC2) và Database (RDS) bên trong môi trường VPC. Lưu trữ Nội dung Tĩnh: Triển khai frontend dạng serverless sử dụng tính năng Static Website Hosting của Amazon S3. Các công việc thực hiện trong tuần: Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Nghiên cứu Kiến thức Database trên Cloud: + Managed vs. Unmanaged (Tại sao nên dùng RDS?). + DB Subnet Groups: Đặt database trong Private Subnet để bảo mật. + Security: Mã hóa dữ liệu (Encryption) và tham chiếu Security Group. 25/08/2025 25/08/2025 FCJ: Tạo Database trên RDS 3 - Thực hành: Khởi tạo RDS MySQL: + Tạo DB Subnet Group bao gồm 2 Private Subnets. + Provision (cấp phát) một instance RDS MySQL (Free Tier). + Quan trọng: Cấu hình tài khoản Master User một cách bảo mật. 26/08/2025 26/08/2025 Tạo Amazon RDS DB instance 4 - Thực hành: Chuỗi Security Group (Security Group Chaining): + Tạo Security Group mới tên DB-SG. + Tác vụ DevOps: Cấu hình Inbound Port 3306 chỉ cho phép từ ID của WebServer-SG (Source: sg-xxxxx), KHÔNG dùng 0.0.0.0/0. 27/08/2025 27/08/2025 Kiểm soát truy cập với Security Groups 5 - Thực hành: Kết nối Ứng dụng với Database: + SSH vào EC2 instance (từ Tuần 3). + Cài đặt mysql-client. + Kiểm tra kết nối: mysql -h \u0026lt;RDS-Endpoint\u0026gt; -u admin -p. 28/08/2025 28/08/2025 Kết nối tới RDS instance 6 - Dự án Static Website: + Tạo S3 Bucket với quyền public read (Cấu hình Block Public Access). + Bật tính năng \u0026ldquo;Static Website Hosting\u0026rdquo;. + Upload file index.html và error.html. 29/08/2025 29/08/2025 FCJ: Host Static Website với S3 Kết quả đạt được trong Tuần 4: Triển khai thành công Managed Database (RDS):\nĐã khởi tạo thành công một MySQL RDS instance bên trong VPC. Hiểu rõ mô hình \u0026ldquo;Shared Responsibility\u0026rdquo; (Trách nhiệm chia sẻ): AWS lo phần hạ tầng và vá lỗi OS, trong khi tôi quản lý dữ liệu và schema. Thiết lập Phân đoạn Mạng An toàn (Kiến trúc 2-Tier):\nĐặt Database nằm trong Private Subnets, đảm bảo database không thể bị truy cập trực tiếp từ Internet công cộng. Ứng dụng kỹ thuật Security Group Chaining (Tham chiếu): Cấu hình firewall cho Database chỉ chấp nhận traffic từ Web Server thông qua Security Group ID. Đây là một thực hành DevSecOps quan trọng giúp tránh việc hardcode địa chỉ IP. Xác thực Kết nối Tầng Ứng dụng:\nCài đặt thành công MySQL client trên EC2 Jumpbox/Web Server. Thiết lập kết nối thành công tới RDS Endpoint, qua đó kiểm chứng cấu hình Route Table và Firewall đã hoạt động đúng. Triển khai Frontend Serverless (S3):\nCấu hình Amazon S3 bucket để host static website. Quản lý Bucket Policies để cho phép quyền đọc (public read access) dành riêng cho tài nguyên web, phân biệt rõ giữa \u0026ldquo;Lưu trữ riêng tư\u0026rdquo; và \u0026ldquo;Hosting công khai\u0026rdquo;. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5: Tính sẵn sàng cao (HA) &amp; Tự động mở rộng","tags":[],"description":"","content":" ⚠️ Lưu ý: Thông tin dưới đây chỉ mang tính chất tham khảo. Vui lòng không sao chép nguyên văn cho báo cáo của bạn.\nMục tiêu Tuần 5: Thiết kế chịu lỗi (Design for Failure): Loại bỏ các điểm lỗi đơn lẻ (Single Points of Failure) bằng cách phân tán traffic qua nhiều Availability Zones (AZs). Triển khai tính đàn hồi (Elasticity): Cấu hình Auto Scaling Groups (ASG) để tự động tăng/giảm số lượng server dựa trên nhu cầu thực tế. Quản lý lưu lượng: Triển khai Application Load Balancer (ALB) đóng vai trò là điểm truy cập duy nhất cho ứng dụng. Các công việc thực hiện trong tuần: Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Nghiên cứu khái niệm High Availability (HA): + Vertical vs. Horizontal Scaling: Phân biệt mở rộng theo chiều dọc (nâng cấp CPU) và chiều ngang (thêm server). + Load Balancing: Các tính năng của ALB (Layer 7) như path-based routing. + Target Groups \u0026amp; Health Checks: Cách ALB phát hiện instance bị lỗi. 01/09/2025 01/09/2025 Tổng quan về Elastic Load Balancing 3 - Thực hành: Tạo Launch Template: + Tạo Launch Template (chuẩn mới thay thế cho Launch Config). + Định nghĩa cấu hình chuẩn: AMI (Web Server từ Tuần 3), Instance Type, Security Groups, và IAM Role. + DevOps Note: Đảm bảo tích hợp User Data để ứng dụng tự khởi chạy. 02/09/2025 02/09/2025 Tạo Launch Template 4 - Thực hành: Triển khai Application Load Balancer (ALB): + Khởi tạo ALB trong Public Subnets (trải dài trên 2 AZs). + Tạo Target Group cho traffic HTTP (Port 80). + Cấu hình Health Checks để ping đường dẫn /index.html. 03/09/2025 03/09/2025 Tạo Application Load Balancer 5 - Thực hành: Cấu hình Auto Scaling Group (ASG): + Tạo ASG sử dụng Launch Template đã tạo. + Định nghĩa công suất (Capacity): Min: 2, Desired: 2, Max: 4. + Gắn ASG vào ALB Target Group. + Stress Test: Giả lập tải CPU cao để kích hoạt sự kiện scale-out (tự động thêm server). 04/09/2025 05/09/2025 Hướng dẫn sử dụng Amazon EC2 Auto Scaling 6 - Kiểm thử khả năng phục hồi: + Chủ động Terminate (xóa) một EC2 instance để kiểm tra tính năng Self-Healing. + Quan sát ASG tự động phát hiện lỗi và khởi tạo instance mới thay thế. 05/09/2025 05/09/2025 Tự kiểm chứng Kết quả đạt được trong Tuần 5: Xây dựng kiến trúc High Availability (HA):\nTriển khai ứng dụng chạy đồng thời trên nhiều Availability Zones (AZs). Đảm bảo rằng nếu một Data Center (AZ) gặp sự cố, ứng dụng vẫn hoạt động bình thường nhờ Load Balancer điều hướng traffic sang AZ còn lại. Áp dụng mô hình Immutable Infrastructure:\nChuyển từ việc khởi tạo instance thủ công sang sử dụng Launch Templates. Tiêu chuẩn hóa cấu hình server (AMI, Security Groups, IAM), đảm bảo mọi server mới sinh ra đều là bản sao chính xác của \u0026ldquo;Gold Image\u0026rdquo;. Làm chủ điều phối lưu lượng (Traffic Orchestration):\nCấu hình Application Load Balancer (ALB) để điều hướng thông minh traffic từ internet đến các instance khỏe mạnh (healthy). Triển khai Health Checks, ngăn chặn ALB gửi request đến các server đang khởi động hoặc bị lỗi. Đạt được khả năng tự phục hồi (Operational Resilience):\nCấu hình thành công Auto Scaling Group (ASG). Kiểm chứng khả năng \u0026ldquo;Self-Healing\u0026rdquo; (Tự chữa lành): Khi một instance bị xóa thủ công, ASG lập tức phát hiện sự cố health check và tự động cung cấp instance mới mà không cần can thiệp của con người. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6: Giám sát &amp; Khả năng quan sát (Monitoring &amp; Observability)","tags":[],"description":"","content":" ⚠️ Lưu ý: Thông tin dưới đây chỉ mang tính chất tham khảo. Vui lòng không sao chép nguyên văn cho báo cáo của bạn.\nMục tiêu Tuần 6: Triển khai Giám sát Chủ động: Chuyển đổi tư duy từ \u0026ldquo;kiểm tra xem web có chạy không\u0026rdquo; sang \u0026ldquo;biết ngay khi nào hệ thống gặp lỗi\u0026rdquo; bằng Amazon CloudWatch. Tập trung hóa Log (Centralized Logging): Cấu hình EC2 để đẩy log hệ điều hành và log ứng dụng về CloudWatch Logs thay vì lưu cục bộ. Tự động hóa Cảnh báo (Alerting): Thiết lập quy trình phản ứng sự cố sử dụng CloudWatch Alarms và Amazon SNS. Các công việc thực hiện trong tuần: Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Nghiên cứu nguyên lý Observability: + Metrics (Chỉ số): Phân biệt Metric tiêu chuẩn (CPU) và Custom Metric (RAM, Disk). + Logs: Khái niệm Log Groups, Log Streams và chính sách lưu trữ (Retention). + Alarms: Các trạng thái (OK, ALARM, INSUFFICIENT_DATA). 08/09/2025 08/09/2025 Amazon CloudWatch là gì? 3 - Thực hành: Cài đặt CloudWatch Agent: + Thách thức: EC2 mặc định không báo cáo chỉ số RAM. + Gắn IAM Role (CloudWatchAgentServerPolicy) cho EC2. + Cài đặt và cấu hình Unified CloudWatch Agent để đẩy thông số % RAM và System Logs lên Cloud. 09/09/2025 09/09/2025 Thu thập metrics và logs với Agent 4 - Thực hành: Tạo Dashboard Vận hành: + Tạo CloudWatch Dashboard tùy chỉnh. + Thêm các widget hiển thị KPI quan trọng: CPU Utilization (Avg/Max), Network In/Out, và Chi phí ước tính (Billing). 10/09/2025 10/09/2025 Sử dụng Amazon CloudWatch Dashboards 5 - Thực hành: Đường ống Cảnh báo (SNS): + Tạo Amazon SNS Topic (ví dụ: DevOps-Alerts). + Subscribe email cá nhân vào topic và xác nhận. + Tạo CloudWatch Alarm: Kích hoạt nếu CPU Utilization \u0026gt; 70% trong 2 chu kỳ 5 phút. + Liên kết hành động của Alarm với SNS Topic. 11/09/2025 11/09/2025 Sử dụng Amazon CloudWatch Alarms 6 - Stress Test \u0026amp; Kiểm chứng: + Chạy công cụ stress (stress-ng) trên EC2 để làm tăng vọt CPU. + Quan sát trạng thái Alarm chuyển sang ALARM. + Xác nhận đã nhận được email cảnh báo từ AWS. 12/09/2025 12/09/2025 Tự kiểm chứng Kết quả đạt được trong Tuần 6: Thiết lập khả năng quan sát toàn diện (Full-Stack Observability):\nNhận ra rằng các chỉ số mặc định của EC2 (cấp Hypervisor) là chưa đủ cho vận hành ứng dụng thực tế. Đã triển khai thành công CloudWatch Unified Agent để thu thập các chỉ số cấp hệ điều hành (Memory/Disk usage) và logs. Triển khai Dashboard giám sát tập trung (\u0026ldquo;Single Pane of Glass\u0026rdquo;):\nTạo được Custom Dashboard cung cấp cái nhìn thời gian thực về sức khỏe hạ tầng. Gom nhóm các chỉ số từ Load Balancer (ELB) và Compute (EC2) vào một giao diện duy nhất để xử lý sự cố nhanh hơn. Tự động hóa phản ứng sự cố:\nXây dựng chuỗi cảnh báo tự động: Metric tăng đột biến → Alarm → SNS → Email. Thiết lập này cho phép đội ngũ phản ứng chủ động với các sự kiện tải cao trước khi hệ thống bị sập, đáp ứng trụ cột \u0026ldquo;Operational Excellence\u0026rdquo; trong Well-Architected Framework. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7: Mạng phân phối nội dung (CDN) &amp; Bảo mật tại biên","tags":[],"description":"","content":" ⚠️ Lưu ý: Thông tin dưới đây chỉ mang tính chất tham khảo. Vui lòng không sao chép nguyên văn cho báo cáo của bạn.\nMục tiêu Tuần 7: Phân phối nội dung toàn cầu: Giảm độ trễ (latency) cho người dùng cuối bằng cách cache các tài nguyên tĩnh (ảnh, CSS, JS) tại các Edge Locations sử dụng Amazon CloudFront. Bảo vệ Origin (Gốc): Triển khai Origin Access Control (OAC) để giới hạn quyền truy cập S3 bucket chỉ dành cho CloudFront, chặn hoàn toàn truy cập trực tiếp từ công cộng. Bảo mật tại biên (Edge Security): Triển khai AWS WAF (Web Application Firewall) để bảo vệ ứng dụng khỏi các cuộc tấn công web phổ biến (như SQLi, XSS) ngay từ lớp ngoài cùng. Các công việc thực hiện trong tuần: Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Nghiên cứu kiến thức CDN: + Edge vs. Region: Hiểu về mạng lưới toàn cầu của AWS. + Hành vi Caching: Khái niệm TTL (Time-to-Live) và Cache Invalidation (Làm mới cache). + Security: SSL/TLS Termination và bắt buộc sử dụng HTTPS. 15/09/2025 15/09/2025 Amazon CloudFront là gì? 3 - Thực hành: CloudFront cho S3 (Static Site): + Tạo CloudFront Distribution trỏ về S3 bucket (từ Tuần 4). + Bước bảo mật quan trọng: Cấu hình Origin Access Control (OAC). + Cập nhật Bucket Policy để chặn truy cập trực tiếp từ internet, chỉ cho phép CloudFront. 16/09/2025 16/09/2025 Giới hạn truy cập S3 Origin 4 - Thực hành: Tối ưu hóa Cache: + Quan sát HTTP Headers trong DevTools (X-Cache: Miss vs. Hit). + Cấu hình tự động nén dữ liệu (Compression - Gzip/Brotli). + Invalidation: Thực hành xóa cache thủ công khi cập nhật file index.html. 17/09/2025 17/09/2025 Quản lý hết hạn Cache 5 - Thực hành: Triển khai AWS WAF: + Tạo Web ACL (Access Control List). + Thêm bộ luật được quản lý sẵn (AWSManagedRulesCommonRuleSet để chặn SQL Injection). + Gắn Web ACL vào CloudFront Distribution. 18/09/2025 18/09/2025 AWS WAF Web ACLs 6 - Kiểm chứng \u0026amp; Đánh giá (Benchmarking): + So sánh tốc độ tải: URL trực tiếp S3 (Độ trễ cao) vs. URL CloudFront (Độ trễ thấp). + Test WAF: Giả lập tấn công (ví dụ: gắn thẻ script vào URL) và xác nhận nhận được lỗi 403 Forbidden. 19/09/2025 19/09/2025 Tự kiểm chứng Kết quả đạt được trong Tuần 7: Tối ưu hóa Hiệu suất (Giảm độ trễ):\nTriển khai Amazon CloudFront để phục vụ nội dung tĩnh từ các Edge Locations (Vị trí biên) gần người dùng nhất. Xác nhận tốc độ tải trang nhanh hơn đáng kể và đạt được Cache Hit Ratio cao, giúp giảm tải cho server gốc (Origin). Bảo mật hóa Origin (S3 Hardening):\nTriển khai Origin Access Control (OAC) - chuẩn bảo mật hiện đại nhất cho kết nối S3-CloudFront. Thành công trong việc thu hồi quyền truy cập công cộng (public read) trên S3 bucket, đảm bảo người dùng chỉ có thể truy cập qua đường dẫn CDN bảo mật (Tuân thủ DevSecOps). Thiết lập Bảo mật vành đai (Perimeter Security):\nTích hợp AWS WAF vào CloudFront distribution. Áp dụng các bộ quy tắc (managed rule sets) để lọc bỏ các lưu lượng độc hại (theo chuẩn OWASP Top 10) trước khi chúng kịp chạm tới hạ tầng ứng dụng. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 9: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 9: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.1-workshop-overview/","title":"Giới thiệu","tags":[],"description":"","content":"Kiến trúc Phi Máy Chủ \u0026amp; Hướng Sự kiện (Serverless \u0026amp; Event-Driven Architecture) Kiến trúc Phi Máy Chủ (Serverless Architecture): Workshop này áp dụng mô hình gốc đám mây (cloud-native) với các dịch vụ như AWS Lambda, Amazon API Gateway, và Amazon DynamoDB. Cách tiếp cận này cho phép mã chạy để phản hồi các yêu cầu mà không cần cấp phát hay quản lý máy chủ, vì AWS sẽ xử lý tất cả việc tự động điều chỉnh quy mô và quản lý cơ sở hạ tầng. Kiến trúc Hướng Sự kiện (Event-Driven Architecture): Cốt lõi của hệ thống hoạt động trên cơ sở hướng sự kiện. Thay vì các dịch vụ liên tục thăm dò dữ liệu, các sự kiện cụ thể—như dữ liệu đọc từ cảm biến IoT hoặc các cuộc gọi API từ người dùng—sẽ kích hoạt các quy trình làm việc tiếp theo. Điều này được điều phối bởi AWS IoT Core và Amazon EventBridge, tạo ra một hệ thống có tính linh hoạt và khả năng mở rộng cao. Tổng quan về Workshop (Workshop Overview) Trong workshop này, bạn sẽ triển khai một nền tảng dữ liệu phi máy chủ toàn diện trên AWS để quản lý giám sát môi trường theo thời gian thực cho thiết lập văn phòng thông minh 8 phòng. Hệ thống tích hợp AWS IoT Core, Lambda, DynamoDB, S3, CloudFront, và Amazon Cognito. Dữ liệu cảm biến được chuyển tiếp từ thiết bị biên (hoặc tập lệnh mô phỏng), được đưa vào AWS, lưu trữ trong các bảng DynamoDB và được xử lý bởi các hàm Lambda để cập nhật bảng điều khiển quản lý. Các sự kiện quan trọng được định tuyến qua EventBridge để kích hoạt cảnh báo, thể hiện một kiến trúc có tính sẵn sàng cao, chi phí thấp và khả năng mở rộng liền mạch.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.1-event1/","title":"Sự kiện 1","tags":[],"description":"","content":"Báo cáo tóm tắt: \u0026ldquo;AWS Cloud Mastery Series #1: AI/ML/GenAI trên AWS\u0026rdquo; Mục tiêu sự kiện Giới thiệu về Foundation Models: Hiểu các khái niệm cốt lõi của Mô hình Nền tảng (FM). Kỹ thuật Prompt Engineering: Hướng dẫn các kỹ thuật đặt câu lệnh (prompt) hiệu quả. Khám phá Amazon Bedrock: Đi sâu vào Generative AI sử dụng Amazon Bedrock. Kiến trúc RAG: Tìm hiểu về Retrieval-Augmented Generation (Thế hệ tăng cường truy xuất) và tích hợp Knowledge Base. Diễn giả Danh Hoàng Hiếu Nghị Lâm Trường Kiệt Đinh Lê Hoàng Anh Điểm nhấn chính Kỹ thuật Prompting Các chiến lược để tạo ra những câu lệnh (prompts) hiệu quả nhằm mang lại kết quả chính xác và phù hợp với ngữ cảnh hơn. RAG (Retrieval-Augmented Generation) Nâng cao năng lực của AI bằng cách nhúng các nguồn dữ liệu bên ngoài. Cho phép mô hình phản hồi với thông tin chính xác, thời gian thực được trích xuất từ dữ liệu nội bộ/độc quyền. Embedding (Mô hình nhúng) Định nghĩa: Sự biểu diễn văn bản dưới dạng số (vectơ) giúp nắm bắt ngữ nghĩa và mối quan hệ giữa các từ. Chức năng: Các mô hình embedding nắm bắt các đặc điểm, ngữ cảnh và sắc thái của văn bản đầu vào. So sánh: Các mô hình embedding phong phú cho phép so sánh sự tương đồng về ngữ nghĩa của văn bản. Hỗ trợ đa ngôn ngữ: Có khả năng xác định ý nghĩa và mối quan hệ giữa các ngôn ngữ khác nhau. Các dịch vụ AWS AI nổi bật Phân tích hình ảnh \u0026amp; tài liệu: Amazon Rekognition, Amazon Textract, Amazon Lookout. Ngôn ngữ \u0026amp; Giọng nói: Amazon Translate, Amazon Transcribe, Amazon Polly, Amazon Comprehend. Tìm kiếm \u0026amp; Dữ liệu: Amazon Kendra, Amazon Personalize. Bài học chính (Key Takeaways) Kỹ thuật Prompting - Chain of Thought (Chuỗi suy luận) Ví dụ theo ngữ cảnh: Cung cấp cho AI các ví dụ trường hợp cụ thể (few-shot prompting). Logic từng bước: Hướng dẫn AI chia nhỏ quy trình giải quyết vấn đề thành các bước tuần tự để cải thiện khả năng suy luận. Các trường hợp sử dụng RAG Độ chính xác: Giảm thiểu \u0026ldquo;ảo giác\u0026rdquo; (hallucinations) bằng cách căn cứ phản hồi vào dữ liệu doanh nghiệp đã được xác minh và cập nhật. Nâng cao Chatbot: Cải thiện khả năng của chatbot bằng cách tích hợp quyền truy cập dữ liệu thời gian thực. Cá nhân hóa: Cho phép chức năng tìm kiếm dựa trên lịch sử người dùng và chân dung (persona) cụ thể. Trích xuất dữ liệu: Truy xuất và tóm tắt các chi tiết giao dịch cụ thể từ các tập dữ liệu lớn. Amazon Titan Embeddings Chức năng: Dịch đầu vào văn bản (từ, cụm từ) thành các vectơ số. Ưu điểm: So sánh embedding tạo ra các phản hồi phù hợp và có ngữ cảnh hơn nhiều so với việc khớp từ khóa đơn thuần. Thông số: Max Tokens: 8,000 Output Vectors: 256, 512, 1,024 Hỗ trợ ngôn ngữ: Đa ngôn ngữ (hơn 100 ngôn ngữ trong bản preview) Áp dụng vào công việc Tôi có kế hoạch nghiên cứu thêm các Dịch vụ AWS AI khác để xác định tính khả thi của chúng khi tích hợp vào các dự án trong tương lai. Trải nghiệm sự kiện Tham dự hội thảo “AI/ML/GenAI trên AWS” là một trải nghiệm cực kỳ giá trị. Tôi đã có cơ hội tiếp thu kiến thức kỹ thuật mới và kết nối với các chuyên gia CNTT khác. Những trải nghiệm chính bao gồm:\nHọc hỏi từ các chuyên gia trong ngành Các chuyên gia từ FACJ đã chia sẻ những bài học thực tiễn tốt nhất (best practices) để triển khai AI trong môi trường thực tế (production). Thông qua các case study thực tế, tôi đã hiểu sâu hơn về cách áp dụng các kỹ thuật prompting nâng cao một cách hiệu quả. Khám phá các dịch vụ AWS AI Qua phần demo của diễn giả, tôi đã nắm được cơ chế hoạt động của các dịch vụ AWS AI khác nhau và quan sát việc ứng dụng chúng trong các tình huống thực tế. Hướng dẫn xây dựng Agent Tôi đã nhận được những thông tin thực tiễn và kiến thức nền tảng cần thiết để bắt đầu xây dựng các AI Agent. Một số hình ảnh sự kiện Tổng kết: Sự kiện này đã cung cấp cho tôi lượng kiến thức đáng kể về AI, có khả năng áp dụng trực tiếp vào các dự án thực tế.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu Tuần 8: Ôn tập kiến thức cho bài kiểm tra giữa kỳ (mid-term test). Thực hiện bài kiểm tra giữa kỳ. Các công việc thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Ôn tập nội dung thi giữa kỳ 27/10/2025 27/10/2025 3 - Ôn tập nội dung thi giữa kỳ 28/10/2025 28/10/2025 4 - Ôn tập nội dung thi giữa kỳ 29/10/2025 29/10/2025 5 - Làm bài trắc nghiệm (quiz) do NotebookLM tạo để ôn thi giữa kỳ 30/10/2025 30/10/2025 6 - Làm bài kiểm tra giữa kỳ 31/10/2025 31/10/2025 Kết quả đạt được trong Tuần 8: Hoàn thành bài kiểm tra giữa kỳ. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.2-blog2/","title":"Hướng dẫn Làm ấm IP và Miền và Di chuyển đến Amazon SES","tags":[],"description":"","content":"Bởi Tyler Holmes | 03 THÁNG 7 NĂM 2025\nDanh mục: Amazon Simple Email Service (SES), Messaging\nGiới thiệu Chuyển giao khối lượng công việc email từ nhà cung cấp dịch vụ email khác (ESP) sang Amazon Simple Email Service (Amazon SES) có thể là một thách thức, vì mỗi khối lượng công việc có thể là duy nhất. Trong bài đăng này, chúng tôi chỉ cho bạn cách sao ấm thành công các địa chỉ IP và miền khi di chuyển đến Amazon SES. Hướng dẫn này nhằm cung cấp tổng quan toàn diện về các thực tiễn tốt nhất sao ấm IP và miền để bạn có thể thực hiện chuyển đổi của mình sang Amazon SES một cách mượt mà nhất có thể. Chúng tôi thảo luận về một số thách thức bạn có thể gặp phải và cách vượt qua những vấn đề phổ biến đó khi chuyển sang nhà cung cấp dịch vụ email mới (ESP).\nHiểu về Email IP và Miền Làm ấm Làm ấm IP và sao ấm miền là các quy trình chiến lược được thiết kế để dần dần giới thiệu một danh tính gửi mới cho các nhà cung cấp hộp thư. Một danh tính gửi mới có thể là một địa chỉ IP dành riêng, miền mới, một miền phụ của miền đó hoặc bất kỳ kết hợp nào trong số chúng. Mục tiêu cốt lõi của việc sao ấm là xây dựng danh tiếng tích cực với các nhà cung cấp hộp thư để email của bạn được gửi đến hộp thư đến thay vì được lọc vào thư mục thư rác hoặc có khả năng bị chặn không được gửi đến hộp thư.\nCác nhà cung cấp hộp thư như Gmail, Yahoo và Outlook cảnh báo về việc bảo vệ người dùng của họ khỏi thư rác và nội dung độc hại. Khi bạn giới thiệu một danh tính gửi mới, các nhà cung cấp hộp thư đánh giá danh tính gửi mới một cách thận trọng. Họ đánh giá việc gửi sớm từ miền và IP để đảm bảo họ đang gửi cho người dùng của nhà cung cấp hộp thư các tin nhắn mà người dùng muốn và không tham gia vào các thực tiễn lạm dụng như thư rác hoặc lừa đảo. Sao ấm cung cấp cho các nhà cung cấp hộp thư cơ hội để quan sát các mẫu gửi, nội dung và số liệu tham gia của bạn, cho phép họ dần dần xây dựng niềm tin vào danh tính gửi mới của bạn.\nSao ấm có thể khác nhau cho mỗi tình huống. Ví dụ, bạn có thể có các IP hoàn toàn được sao ấm, nhưng nếu miền gửi của bạn là mới, bạn sẽ có thể phải sao ấm nó cũng nhưng bạn sẽ không cần phải lo lắng về sao ấm IP nhiều. Một tình huống phổ biến khác là thêm IP mới nhưng gửi với miền được thiết lập. Trong trường hợp này, IP sẽ cần sao ấm, nhưng miền chính nó đang giúp sao ấm vì nó đã có danh tiếng được thiết lập. Khi bạn có net mới IP và net mới miền, bạn sẽ phải sao ấm chúng cùng nhau. Các thực tiễn tốt nhất sao ấm mà chúng tôi nêu trong bài đăng này, chẳng hạn như bắt đầu từ từ và nhắm mục tiêu đến những người đăng ký được tham gia cao nhất, áp dụng cho tình huống của bạn.\nTại sao Làm ấm là Quan trọng Làm ấm là rất cần thiết vì nhiều lý do, mỗi lý do góp phần vào thành công tổng thể và độ tin cậy của các chiến dịch email marketing của bạn:\n1. Xây dựng Niềm tin với Nhà cung cấp Hộp thư Danh tiếng người gửi tích cực là quan trọng đối với khả năng gửi email. Các nhà cung cấp hộp thư sử dụng các thuật toán phức tạp để đánh giá danh tiếng của những người gửi, và sao ấm giúp họ xây dựng niềm tin vào danh tính gửi mới của bạn.\n2. Tránh các Vấn đề về Khả năng gửi Ban đầu Khi bạn chuyển sang một ESP mới hoặc giới thiệu một danh tính gửi mới, cảm thấy cơ bản để trải nghiệm một sự sụt giảm ban đầu trong các số liệu khả năng gửi, chẳng hạn như tỷ lệ mở thấp hơn, tỷ lệ nhấp chuột hoặc tỷ lệ nảy cao hơn. Sao ấm có thể giảm nhẹ những vấn đề này bằng cách cấp cho các nhà cung cấp hộp thư thời gian để thích ứng với các mẫu gửi mới của bạn, cho dù đó là miền mới, miền phụ hoặc cơ sở hạ tầng IP mới.\n3. Duy trì Hành vi gửi Nhất quán Sao ấm khuyến khích bạn duy trì một nhịp độ gửi ổn định và có thể dự đoán được. Những thay đổi đột ngột, đáng kể về khối lượng gửi, nội dung hoặc tần suất có thể kích hoạt bộ lọc thư rác hộp thư vì những thay đổi như vậy có thể chỉ ra rằng người gửi đã bị xâm phạm hoặc tham gia vào các thực tiễn lạm dụng. Ngay cả những bất thường như những thay đổi lớn về khối lượng hoặc thông lượng trong các sự kiện theo mùa như Thứ Sáu Đen cũng có thể được hiểu là tiêu cực, và các nhà cung cấp hộp thư có cách tiếp cận thận trọng khi họ phát hiện những bất thường như vọt tăng đột ngột trong khối lượng.\n4. Thành công về Khả năng gửi Dài hạn Đó là một quan niệm sai lầm rằng sao ấm được thực hiện chỉ một lần. Trên thực tế, bạn cần phải duy trì khối lượng giao thông và nhịp độ gửi để giữ những danh tính gửi đó ấm. Ngoài ra, nếu bạn có kế hoạch tăng khối lượng đáng kể, ví dụ từ 1M đến 5M hoặc 5M đến 25M, bạn cần phải sao ấm lên những khối lượng đó. Những bước nhảy lớn này trong khối lượng trông đáng ngờ với các nhà cung cấp hộp thư ngay cả khi bạn đã gửi liên tục.\n5. Thích ứng với Các Thay đổi của Nhà cung cấp Hộp thư Các nhà cung cấp hộp thư cũng liên tục cập nhật các thuật toán của họ để tốt hơn phát hiện thư rác và hành vi lạm dụng. Nếu bạn xem sao ấm là một quá trình liên tục và liên tục giám sát khả năng gửi của bạn và các tín hiệu tham gia, bạn có thể thực hiện các điều chỉnh đối với chiến lược gửi của bạn khi cần thiết, đảm bảo rằng email của bạn tiếp tục đến hộp thư đến, ngay cả khi hành vi hộp thư và khán giả thay đổi.\nNhững Thách thức Phổ biến để Di chuyển Lưu lượng truy cập và Làm ấm lên một ESP Mới Chuyển giao lưu lượng email của bạn sang một ESP mới có thể có những thách thức duy nhất yêu cầu cân nhắc và kế hoạch chiến lược cẩn thận để vượt qua. Những thách thức này bao gồm những điều sau đây:\nLưu lượng truy cập được điều khiển bởi sự kiện – Nếu tất cả email của bạn được điều khiển bởi sự kiện, thật khó để kiểm soát khối lượng và thông lượng.\nNhiều miền gửi – Có nhiều miền gửi với các khối lượng giao thông và thông lượng khác nhau có thể làm phức tạp quá trình chuyển đổi.\nKhông có IP được chia sẻ – Một số tổ chức không được phép sử dụng các nhóm IP được chia sẻ.\nThiếu dữ liệu tham gia – Thiếu dữ liệu liên quan đến tham gia có thể khiến việc tối ưu hóa quá trình sao ấm trở nên khó khăn.\nThông tin nảy và hủy đăng ký lỗi thời – Không có thông tin nảy và hủy đăng ký cập nhật trong ESP hiện tại của bạn có thể dẫn đến các vấn đề về khả năng gửi.\nMiền cấp hai duy nhất – Bạn hiện đang gửi thư của mình từ miền cấp hai, chẳng hạn như example.com, mà không có các miền phụ riêng biệt cho các trường hợp sử dụng logic như giao dịch hoặc tiếp thị.\nNhững khoảng thời gian chặt chẽ – Hợp đồng kết thúc hoặc các lý do khác có thể áp đặt khoảng thời gian chặt chẽ cho quá trình chuyển đổi.\nNhững Thách thức đối với Nhà cung cấp dịch vụ độc lập (ISV) và Nhà cung cấp Phần mềm-như-một-Dịch vụ (SaaS) – Những tổ chức này thường không có quyền kiểm soát hoàn toàn đối với khối lượng, nội dung, danh sách hoặc tính nhất quán gửi của khách hàng của họ. Họ cũng có thể không có quyền truy cập trực tiếp vào DNS cần thiết để cập nhật và căn chỉnh miền gửi và xác thực.\nChiến lược cho Sao ấm và Di chuyển thành công Danh sách sau đây không phù hợp với mọi trường hợp, và nhiều khách hàng sẽ sử dụng hơn một chiến lược để giải quyết những thách thức của họ và làm mượt quá trình chuyển đổi của họ sang Amazon SES:\n1. Gửi đến Khán giả Tốt nhất của Bạn Trước Điều quan trọng nhất bạn cần làm khi chuyển sang một ESP mới là gửi đến những người nhận hoạt động cao nhất và tích cực nhất của bạn trên ESP mới và để những phân khúc ít hoạt động hoặc rủi ro hơn trên ESP trước đó cho đến khi bạn sẵn sàng chuyển đổi đầy đủ. Ví dụ, nếu bạn là người gửi hàng ngày gửi đến 1M địa chỉ một ngày và có tỷ lệ mở khoảng 20%, bạn cần bắt đầu onboarding với các phân khúc bao gồm những người đang mở. Một chiến lược tốt là bắt đầu với những người mở cửa từ 30 ngày cuối cùng, sau đó chuyển đến những người mở 31–90 ngày, v.v.\n2. Dần dần Di chuyển Người đăng ký Ít tham gia của Bạn Sau khi bạn đã chuyển giao các phân khúc tích cực nhất của mình, bạn có thể bắt đầu bao gồm những người ít tham gia một chút. Bạn có thể rắc chúng vào với các phân khúc tham gia hơn để nếu bạn nhận được nảy hoặc phàn nàn, nó được lọc bởi các phân khúc tham gia hơn. Hãy chắc chắn tiếp tục theo dõi các vấn đề và ngay lập tức dừng tăng khối lượng công việc của bạn nếu bạn gặp các vấn đề về khả năng gửi như tăng tỷ lệ nảy hoặc spam.\n3. Bắt đầu với Khối lượng công việc Dự đoán được Bắt đầu với khối lượng công việc không phụ thuộc vào thời gian, chẳng hạn như các bản tin, dễ dàng kiểm soát và theo dõi hơn.\n4. Batch Event-driven Messages Đối với các tin nhắn được điều khiển bởi sự kiện mà không phụ thuộc vào thời gian, hãy cố gắng để batch và phân tán chúng để quản lý khối lượng.\n5. Sử dụng Quy trình Sao ấm Tự động Tiêu chuẩn và IP dành riêng được quản lý có thể giúp quản lý khối lượng hàng ngày bằng cách cho phép các mức lưu lượng được xác định trước trên các IP dành riêng của bạn và tràn ra ngoài các nhóm IP được chia sẻ khi khối lượng email đã đạt đến một mức mà chúng tôi cho là đủ cho các IP dành riêng của bạn. Điều này phụ thuộc vào tiến trình sao ấm của bạn cho đến nay. Tiêu chuẩn dành riêng là tăng tĩnh 45 ngày, nhưng được quản lý dành riêng có một quá trình tinh vi hơn. Để tìm hiểu thêm, hãy tham khảo Địa chỉ IP dành riêng cho Amazon SES.\n6. Sử dụng Chiến lược các Nhóm IP được Chia sẻ Sử dụng các nhóm IP được chia sẻ cho khối lượng công việc không yêu cầu IP dành riêng. Vì có khối lượng liên tục đã đi qua những IP này, chúng tha thứ hơn một chút so với IP dành riêng được sao ấm.\n7. Chuyển đổi Dần dần sang IP Dành riêng Bắt đầu với IP được chia sẻ và dần dần chuyển sang IP dành riêng khi chúng sao ấm.\n8. Chuyển đổi Dần dần sang Miền phụ Logic Chia nhỏ lưu lượng truy cập của bạn thành các khối lượng công việc logic có thể có khối lượng liên tục và thông lượng. Ngay cả một cái gì đó đơn giản như marketing.example.com và transactional.example.com thì tốt hơn việc gửi thư từ example.com\n9. Onboard Khách hàng Mới trên ESP Mới Đối với ISV và Nhà cung cấp SaaS, hãy cân nhắc onboarding các khách hàng mới trực tiếp trên ESP mới để thu thập dữ liệu ban đầu và thử nước. Các khách hàng mới đã cần được sao ấm, vì vậy nếu bạn sao ấm chúng trên Amazon SES thay vì ESP di sản của bạn, bạn không cần phải trải qua một quy trình sao ấm hai lần.\nChuẩn bị để Di chuyển Email Traffic đến Amazon SES Trước khi bạn di chuyển chương trình email của mình sang Amazon SES, điều quan trọng là phải lập tài liệu và sắp xếp thiết lập hiện tại của bạn hoàn toàn. Công việc chuẩn bị này sẽ tạo nền tảng cho một quá trình sao ấm và di chuyển thành công.\nDanh sách kiểm tra Chuẩn bị Lập tài liệu các trường hợp sử dụng của bạn – Phân loại các trường hợp sử dụng của bạn là tiếp thị hoặc giao dịch. Điều này sẽ giúp bạn hiểu bản chất của các email bạn gửi và cách chúng nên được xử lý.\nLập tài liệu các miền gửi của bạn – Bao gồm các tên \u0026ldquo;từ\u0026rdquo; được liên kết với mỗi miền. Điều này sẽ hỗ trợ trong việc ánh xạ miền thích hợp tới loại email tương ứng. Lý tưởng nhất là bạn nên tránh gửi từ miền gốc của bạn. Ví dụ, sử dụng miền phụ như email.brand.com thay vì brand.com. Xem xét và lập tài liệu xác thực của bạn (ví dụ, SPF, DKIM hoặc DMARC). Trong một số trường hợp, bạn có thể không cần căn chỉnh tất cả chúng, nhưng bạn chắc chắn sẽ cần phải căn chỉnh DMARC như một phần của các yêu cầu người gửi hàng loạt.\nÁnh xạ các trường hợp sử dụng sang các miền gửi và từ tên – Tạo một tương ứng rõ ràng để đảm bảo các email phù hợp được gửi từ các miền thích hợp. Tối thiểu, đó là một thực tiễn tốt nhất để có các miền phụ riêng biệt cho các trường hợp sử dụng email giao dịch và khuyến mãi, chẳng hạn như transactional.brand.com và promo.brand.com.\nLập tài liệu khối lượng và thông lượng tối đa – Chụp thông tin này cho mỗi trường hợp sử dụng được ánh xạ tới các miền gửi của bạn. Điều này sẽ giúp bạn hiểu quy mô của hoạt động email của bạn và lên kế hoạch kiến trúc và chiến lược sao ấm của bạn cho phù hợp.\nDự kiến một sự sụt giảm tạm thời trong các số liệu khả năng gửi – Trong khi chuyển sang một ESP mới, bạn có thể trải nghiệm một biến động ngắn hạn trong các số liệu như tỷ lệ mở và tỷ lệ nhấp chuột. Đây là một điều phổ biến xảy ra và không nên được coi là một thất bại của dịch vụ. Đó là một phần mong đợi của quá trình di chuyển khi các nhà cung cấp hộp thư thích ứng với danh tính gửi mới của bạn. Bằng cách theo dõi chặt chẽ tỷ lệ nảy và phàn nàn của bạn, bạn có thể thực hiện các điều chỉnh chủ động đối với kế hoạch tăng của bạn để đảm bảo một quá trình chuyển đổi mượt mà.\nLập tài liệu kế hoạch sao ấm của bạn – Có một kế hoạch để dần dần tăng giao thông cho mỗi danh tính và giám sát các số liệu tham gia. Lên kế hoạch cho cách xử lý tỷ lệ nảy hoặc phàn nàn cao.\nKế hoạch Sao ấm Mẫu Bảng sau đây cho thấy một kế hoạch sao ấm mẫu. Nhận thấy rằng các ngày được phân loại theo các nhà cung cấp hộp thư lớn. Điều này là vì những nhà cung cấp này đều chấp nhận thư mới với các tỷ lệ khác nhau. Phân loại theo cách này là một thực tiễn được khuyến nghị, nhưng nếu bạn không thể phân khúc chi tiết đó, bạn có thể sử dụng cột Tổng số Hàng ngày làm hướng dẫn. Dịch vụ IP dành riêng được quản lý AWS tự động làm phân đoạn hóa và điều chỉnh ở cấp độ miền cho bạn.\nKế hoạch sau đây là một ramp điển hình. Bạn có thể tấn công tích cực hơn tỷ lệ tham gia tổng thể của bạn càng cao, vì vậy nếu bạn ở mức 40–60% tham gia, bạn có thể sử dụng sao ấm này. Nếu tỷ lệ của bạn thấp hơn, bạn có thể muốn thận trọng hơn một chút. Hãy chắc chắn thích ứng khi bạn bước vào kế hoạch sao ấm của mình vì bạn có thể cần duy trì cùng một tỷ lệ trong vài ngày hoặc thậm chí quay lại một bước nếu bạn đang trải nghiệm các xu hướng tiêu cực như sự sụt giảm khả năng gửi hoặc tham gia. Liên tục giám sát các số liệu của bạn trong thời gian quan trọng này.\nNgày @gmail.com @hotmail.com @outlook.com @yahoo.com @icloud.com @aol.com Khác Tổng hàng ngày 1 150 150 150 150 150 150 150 1.050 2 300 300 300 300 300 300 300 2.100 3 600 600 600 600 600 600 600 4.200 4 1.200 1.200 1.200 1.200 1.200 1.200 1.200 8.400 5 2.400 2.400 2.400 2.400 2.400 2.400 2.400 16.800 6 5.000 5.000 5.000 5.000 5.000 5.000 5.000 35.000 7 10.000 10.000 10.000 10.000 10.000 10.000 10.000 70.000 8 20.000 20.000 20.000 20.000 20.000 20.000 20.000 140.000 9 40.000 40.000 40.000 40.000 40.000 40.000 40.000 280.000 10 80.000 80.000 80.000 80.000 80.000 80.000 80.000 560.000 11 150.000 150.000 150.000 150.000 150.000 150.000 150.000 1.050.000 12 300.000 300.000 300.000 300.000 300.000 300.000 300.000 2.100.000 13 425.000 425.000 425.000 425.000 425.000 425.000 425.000 2.975.000 14 500.000 500.000 500.000 500.000 500.000 500.000 500.000 3.500.000 15 600.000 600.000 600.000 600.000 600.000 600.000 600.000 4.200.000 16 650.000 650.000 650.000 650.000 650.000 650.000 650.000 4.550.000 17 700.000 700.000 700.000 700.000 700.000 700.000 700.000 4.900.000 18 800.000 800.000 800.000 800.000 800.000 800.000 800.000 5.600.000 19 900.000 900.000 900.000 900.000 900.000 900.000 900.000 6.300.000 20 1.000.000 1.000.000 1.000.000 1.000.000 1.000.000 1.000.000 1.000.000 7.000.000 21 1.100.000 1.100.000 1.100.000 1.100.000 1.100.000 1.100.000 1.100.000 7.700.000 22 1.200.000 1.200.000 1.200.000 1.200.000 1.200.000 1.200.000 1.200.000 8.400.000 23 1.300.000 1.300.000 1.300.000 1.300.000 1.300.000 1.300.000 1.300.000 9.100.000 24 1.400.000 1.400.000 1.400.000 1.400.000 1.400.000 1.400.000 1.400.000 9.800.000 25 1.500.000 1.500.000 1.500.000 1.500.000 1.500.000 1.500.000 1.500.000 10.500.000 26 1.600.000 1.600.000 1.600.000 1.600.000 1.600.000 1.600.000 1.600.000 11.200.000 27 1.700.000 1.700.000 1.700.000 1.700.000 1.700.000 1.700.000 1.700.000 11.900.000 28 1.800.000 1.800.000 1.800.000 1.800.000 1.800.000 1.800.000 1.800.000 12.600.000 29 1.900.000 1.900.000 1.900.000 1.900.000 1.900.000 1.900.000 1.900.000 13.300.000 30 2.000.000 2.000.000 2.000.000 2.000.000 2.000.000 2.000.000 2.000.000 14.000.000 31 2.100.000 2.100.000 2.100.000 2.100.000 2.100.000 2.100.000 2.100.000 14.700.000 32 2.200.000 2.200.000 2.200.000 2.200.000 2.200.000 2.200.000 2.200.000 15.400.000 33 2.300.000 2.300.000 2.300.000 2.300.000 2.300.000 2.300.000 2.300.000 16.100.000 34 2.400.000 2.400.000 2.400.000 2.400.000 2.400.000 2.400.000 2.400.000 16.800.000 35 2.500.000 2.500.000 2.500.000 2.500.000 2.500.000 2.500.000 2.500.000 17.500.000 36 2.600.000 2.600.000 2.600.000 2.600.000 2.600.000 2.600.000 2.600.000 18.200.000 37 2.700.000 2.700.000 2.700.000 2.700.000 2.700.000 2.700.000 2.700.000 18.900.000 38 2.800.000 2.800.000 2.800.000 2.800.000 2.800.000 2.800.000 2.800.000 19.600.000 39 2.900.000 2.900.000 2.900.000 2.900.000 2.900.000 2.900.000 2.900.000 20.300.000 40 3.000.000 3.000.000 3.000.000 3.000.000 3.000.000 3.000.000 3.000.000 21.000.000 Các Thực tiễn Tốt nhất cho một Sao ấm IP thành công Một sao ấm IP thành công liên quan đến một cách tiếp cận chiến lược kết hợp chuẩn bị kỹ thuật, những người đăng ký tham gia, nội dung thuyết phục và giám sát liên tục.\n1. Đảm bảo Sự Sẵn sàng Kỹ thuật Cấu hình các bản ghi DNS và thiết lập SPF, DKIM, DMARC, và BIMI để nội dung email của bạn tuân thủ các thực tiễn tốt nhất. Hãy chắc chắn DMARC của bạn được căn chỉnh nếu bạn đang gửi trên nhiều ESP hoặc ứng dụng.\n2. Sử dụng Danh sách Gửi được tham gia, Dựa trên Quyền Sử dụng danh sách sạch, opt-in của những người đăng ký quan tâm đến nội dung của bạn. Để biết thêm thông tin, hãy tham khảo Tối ưu hóa Khả năng gửi Email: Cách tiếp cận Lập kế hoạch Danh sách và Giám sát Trung tâm Người dùng.\n3. Cung cấp Nội dung Email Thuyết phục, Có giá trị Gửi nội dung cộng hưởng với khán giả của bạn và khuyến khích tham gia.\n4. Dần dần Tăng Khối lượng và Nhịp độ Gửi Bắt đầu với một khối lượng email nhỏ và dần dần tăng theo thời gian để cho phép các nhà cung cấp hộp thư quan sát các mẫu gửi của bạn.\n5. Duy trì Tính nhất quán trong Hành vi gửi Tránh những thay đổi đột ngột, đáng kể về khối lượng gửi, nội dung hoặc tần suất.\n6. Liên tục Giám sát và Tối ưu hóa Các số liệu Chính Theo dõi tỷ lệ mở, tỷ lệ nhấp chuột, tỷ lệ nảy và tỷ lệ phàn nàn, và thực hiện các điều chỉnh khi cần thiết. Để biết thêm thông tin, hãy tham khảo Amazon SES – Thiết lập thông báo cho nảy và phàn nàn.\n7. Bảo trì Danh tiếng Người gửi Liên tục Kiểm toán dòng dữ liệu, tăng lên dần dần những thay đổi, và tuân theo các thực tiễn tiếp thị email phát triển.\nĐiều hướng Những Thách thức về Khả năng gửi Ban đầu Khi chuyển sang một ESP mới, bạn có thể gặp phải một số thách thức khả năng gửi ban đầu. Điều quan trọng là giám sát và thực hiện cảnh báo nếu bạn quan sát thấy tỷ lệ nảy hoặc phàn nàn tăng. Nếu bạn có những thách thức, bạn cần xử lý chúng nhanh chóng. Duy trì cùng một khối lượng hoặc thậm chí giảm khối lượng ngày hôm sau nếu bạn gặp những vấn đề này:\n1. Bùng nổ trong Tỷ lệ Nảy Cứng Mang các danh sách triệt tiêu của bạn từ ESP bạn đang tắt, nhưng nếu ESP trước đó của bạn không quản lý những điều này tốt hoặc bạn tải một số địa chỉ cũ mà bạn không biết, cảm thấy cơ bản để trải nghiệm các đơn vị nảy cứng ở đầu. Nếu điều này xảy ra, làm chậm tăng khối lượng của bạn hoặc thậm chí dừng tăng cho đến khi mọi thứ ổn định. Điều quan trọng hơn là sao ấm đúng cách so với nó để đến mức độ sản xuất gửi càng nhanh càng tốt. Đây là một lý do khác tại sao lúc nào cũng tốt nhất để bắt đầu với các phân khúc tham gia nhất của bạn.\n2. Tăng Phàn nàn Spam Email có thể đạt đến những người nhận đã lọc chúng trước đây, dẫn đến nhiều phàn nàn spam. Thay đổi danh tính cũng có thể khiến người nhận của bạn nhấn nút spam vì họ không nhận ra nó. Thông báo những thay đổi danh tính trước khi thay đổi ESP để giảm nguy cơ của một vấn đề.\n3. Sự Kinh sợ Tăng của Nhà cung cấp Hộp thư Các nhà cung cấp hộp thư sẽ giám sát chặt chẽ những người gửi mới để xác nhận họ không tham gia vào các hoạt động độc hại. Điều này có thể chuyển hướng email tới bộ lọc thư rác ban đầu hoặc thậm chí bị điều chỉnh nếu bạn đạt đến giới hạn khối lượng hoặc thông lượng. Gmail được biết là nghiêm ngặt. Các IP dành riêng được quản lý Amazon SES sử dụng dữ liệu của chúng tôi để biết bao nhiêu thư các nhà cung cấp hộp thư lớn sẽ chấp nhận trong khi bạn đang sao ấm và giữ bạn khỏi vượt quá các giới hạn của họ.\n4. Điều chỉnh ESP và Giới hạn Gửi ESP mới có thể có các quy tắc khắt khe hơn về khối lượng email có thể được gửi đến các nhà cung cấp hộp thư riêng lẻ. Amazon SES có giới hạn tài khoản cho khối lượng hàng ngày và thông lượng tối đa, vì vậy điều chỉnh của bạn là những gì bạn sẽ cần. Để tìm hiểu thêm, hãy tham khảo Tăng các hạn ngạch gửi Amazon SES của bạn trong Hướng dẫn Nhà phát triển Amazon SES.\nDuy trì Danh tiếng IP Sau khi Sao ấm Sao ấm IP là một quá trình liên tục. Ngay cả sau khi giai đoạn sao ấm ban đầu, điều quan trọng là duy trì danh tiếng người gửi của bạn bằng cách liên tục quản lý chương trình email của bạn. Tham gia người đăng ký của bạn có thể dao động khi danh sách của bạn phát triển và thay đổi. Tương tự, tăng khối lượng giao thông email cho một chiến dịch theo mùa sẽ yêu cầu điều chỉnh quá trình sao ấm của bạn. Bạn cần phải chủ động và điều chỉnh chiến lược sao ấm IP của bạn.\nKiểm toán dòng dữ liệu và các chiến dịch và giám sát các nguồn danh sách email, thực tiễn thu thập dữ liệu và hiệu suất chiến dịch. Khi giới thiệu các yếu tố mới, hãy làm điều đó từng bước để tránh kích hoạt các vấn đề danh tiếng. Để cho phép thời gian cho danh tiếng của bạn ổn định, hãy cung cấp ít nhất một tháng để một đường cơ sở mới được thiết lập sau khi những thay đổi chương trình lớn. Tương tác với khách hàng, cung cấp giá trị và thực hiện các chiến dịch tái tham gia để nuôi dưỡng các mối quan hệ khách hàng của bạn. Tuân thủ các thực tiễn tiếp thị email phát triển, bao gồm các giao thức xác thực thích hợp và công nghệ mới nổi. Hãy chủ động và theo dõi danh tiếng miền và IP để bạn có thể nhanh chóng giải quyết các vấn đề khả năng gửi phát sinh. Để tìm hiểu thêm về việc giám sát các công cụ hộp thư như Google Postmaster, hãy tham khảo Hiểu Google Postmaster Tools (phàn nàn spam) cho những người gửi Amazon SES.\nKết luận Chuyển giao chương trình email của bạn sang một ESP mới như Amazon SES có thể có vẻ phức tạp, nhưng nó có thể nhanh chóng và liền mạch nếu bạn tuân theo các thực tiễn tốt nhất được giải thích trong bài đăng này. Sao ấm IP là một thành phần quan trọng của quá trình này vì nó giúp xây dựng danh tiếng người gửi tích cực với các nhà cung cấp hộp thư và thúc đẩy việc gửi email đáng tin cậy.\nTrong suốt hướng dẫn này, chúng tôi đã đề cập đến các khía cạnh chính của sao ấm IP và di chuyển email, từ việc hiểu tầm quan trọng của thực tiễn này đến xác định những thách thức phổ biến và nêu các chiến lược hiệu quả cho một quá trình chuyển đổi thành công. Bằng cách tuân theo các thực tiễn tốt nhất như tạo điều kiện sẵn sàng kỹ thuật, sử dụng cơ sở người đăng ký tham gia, cung cấp nội dung thuyết phục và dần dần tăng khối lượng gửi, bạn có thể điều hướng các thách thức khả năng gửi ban đầu và thiết lập một nền tảng vững chắc cho thành công chương trình email dài hạn.\nTuy nhiên, công việc không dừng lại khi giai đoạn sào ấm ban đầu hoàn tất. Duy trì danh tiếng IP và điều chỉnh chiến lược của bạn khi chương trình email và sự tham gia của người đăng ký phát triển là một quá trình liên tục. Liên tục giám sát các số liệu chính, kiểm toán dòng dữ liệu và cập nhật với các thực tiễn tiếp thị email phát triển là rất quan trọng để duy trì khả năng gửi. Danh tiếng người gửi lâu dài và mối quan hệ lâu dài với danh sách và người nhận của bạn là một số lợi ích chính của các thực tiễn tốt nhất sau đây. Chuyển sang một ESP mới là một nỗ lực đáng kể, nhưng với sự chuẩn bị thích hợp, thực hiện và cam kết duy trì liên tục, quá trình di chuyển của bạn có thể mượt mà và thành công.\nVề Tác giả Tyler Holmes Tyler là một Kiến trúc sư Giải pháp Chuyên gia Cao cấp. Anh ấy có rất nhiều kinh nghiệm trong lĩnh vực giao tiếp như một cố vấn, một SA, một từng làm việc và lãnh đạo ở tất cả các cấp độ từ Startup đến Fortune 500. Anh ấy đã dành hơn 14 năm trong bán hàng, tiếp thị và hoạt động dịch vụ, làm việc cho các cơ quan, công ty tư vấn và thương hiệu, xây dựng các nhóm và tăng doanh thu.\nTài nguyên cho Khả năng gửi Hướng dẫn Nhà phát triển Amazon SES Tài liệu API Amazon SES Hạn ngạch dịch vụ trong Amazon SES Điểm cuối Amazon SES và hạn ngạch Giá Amazon SES Amazon Pinpoint Bắt đầu với Amazon Pinpoint Tags: Amazon SES, Email Deliverability, IP Warming, Domain Warming, Email Migration, Email Marketing\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"Hệ thống Quản lý Văn phòng Thông minh cho Phòng Nghiên cứu Giải pháp AWS Serverless hợp nhất cho giám sát và điều khiển văn phòng thông minh theo thời gian thực 1. Tóm tắt điều hành Hệ thống Quản lý Văn phòng Thông minh (Smart Office Management System) được đề xuất bởi Nhóm Skyscraper từ FPTU HCM Campus, lấy cảm hứng từ sự vận hành xuất sắc quan sát được trong chuyến đi thực tế đến văn phòng AWS tại TP. Hồ Chí Minh. Việc quản lý văn phòng truyền thống hiện nay thiếu khả năng hiển thị thời gian thực về điều kiện phòng (nhiệt độ, độ ẩm, ánh sáng) và phụ thuộc nhiều vào sự giám sát thủ công. Để giải quyết vấn đề này, chúng tôi đề xuất xây dựng một Bảng điều khiển Quản lý (Management Console) tập trung, được xây dựng trên kiến trúc AWS Serverless hoàn chỉnh. Bằng cách tận dụng các dịch vụ như AWS IoT Core, Lambda và DynamoDB, hệ thống thu thập dữ liệu cảm biến mỗi 2-5 phút để hỗ trợ giám sát thời gian thực và cho phép quản trị viên quản lý cấu hình thiết bị từ xa. Dự án này cũng đóng vai trò là chiến lược \u0026ldquo;First Cloud AI Journey\u0026rdquo;, giúp nhóm thu hẹp khoảng cách giữa kiến thức lý thuyết và ứng dụng thực tế của Điện toán Đám mây.\n2. Tuyên bố vấn đề Vấn đề hiện tại Hiện nay, việc quản lý môi trường văn phòng trong các phòng lab nghiên cứu đòi hỏi sự can thiệp thủ công để kiểm tra trạng thái thiết bị (đèn, điều hòa) và điều kiện môi trường. Các quản lý thường thiếu dữ liệu cần thiết để đưa ra quyết định sáng suốt về việc sử dụng năng lượng hoặc sự thoải mái của phòng. Việc vận hành thiết bị theo lịch trình cố định (ví dụ: 8 giờ sáng đến 5 giờ chiều) mà không quan tâm đến mức độ sử dụng thực tế hoặc các yếu tố môi trường dẫn đến lãng phí năng lượng. Hơn nữa, nếu không có bảng điều khiển tập trung, quản trị viên không thể nhanh chóng phát hiện các bất thường hoặc cấu hình cài đặt cho nhiều phòng một cách hiệu quả.\nGiải pháp Nền tảng sử dụng AWS IoT Core để tiếp nhận dữ liệu MQTT từ cảm biến phòng, AWS Lambda và API Gateway cho logic xử lý backend, Amazon DynamoDB để lưu trữ nhật ký cảm biến và cấu hình phòng, cùng với Amazon S3 kết hợp CloudFront để lưu trữ bảng điều khiển quản lý web. Quyền truy cập được bảo mật nghiêm ngặt thông qua Amazon Cognito. Amazon EventBridge được sử dụng để xử lý các tác vụ tự động hóa theo lịch trình, trong khi Amazon SNS đảm bảo thông báo kịp thời cho các cảnh báo hệ thống. Giải pháp này thay thế việc theo dõi thủ công bằng một bảng điều khiển quản lý kỹ thuật số, thời gian thực, có khả năng giám sát nhiều phòng cùng lúc.\nLợi ích và hoàn vốn đầu tư (ROI) Hệ thống Quản lý Văn phòng Thông minh nâng cao hiệu quả vận hành bằng cách cung cấp một giao diện giám sát và cấu hình duy nhất. Nó trao quyền cho quản lý phòng lab điều khiển thiết bị từ xa và đưa ra quyết định dựa trên dữ liệu. Ngoài những cải tiến về vận hành, dự án cung cấp một nền tảng serverless có thể tái sử dụng cho các nghiên cứu IoT trong tương lai tại trường đại học.\nChi phí vận hành hàng tháng ước tính khoảng $1.81 USD, tận dụng AWS Free Tier cho các dịch vụ như Lambda, API Gateway và DynamoDB. Chi phí chính bao gồm CloudFront ($1.27) và CloudWatch ($0.25), tổng cộng khoảng $21.72 USD mỗi năm. Vì hệ thống tận dụng phần cứng ESP32 và cảm biến hiện có, không có thêm chi phí vốn đầu tư. Hệ thống mang lại giá trị ngay lập tức thông qua việc tiết kiệm thời gian và giảm nỗ lực quản lý.\n3. Kiến trúc giải pháp Hệ thống Smart Office áp dụng kiến trúc AWS hoàn toàn serverless được tối ưu hóa cho hiệu quả chi phí và khả năng mở rộng. Dữ liệu từ nhiều hub cảm biến được truyền đến AWS IoT Core, được xử lý bởi các hàm Lambda và lưu trữ trong DynamoDB để giám sát thời gian thực và quản lý cấu hình. EventBridge tự động hóa các hành động thiết bị theo lịch trình, trong khi SNS xử lý thông báo hệ thống. Bảng điều khiển web được lưu trữ trên S3 và phân phối an toàn qua CloudFront, với xác thực người dùng được quản lý thông qua Amazon Cognito. Kiến trúc này giảm thiểu chi phí vận hành và đảm bảo độ tin cậy cao cho việc kiểm soát môi trường thông minh.\nDịch vụ AWS sử dụng AWS IoT Core: Tiếp nhận và quản lý dữ liệu MQTT từ các hub phòng thông minh, cho phép giao tiếp an toàn giữa thiết bị biên và đám mây. AWS Lambda: Thực thi logic backend để xử lý dữ liệu cảm biến, xử lý các yêu cầu API và thực hiện các lệnh quản lý (Tính toán Serverless). Amazon API Gateway: Cung cấp các điểm cuối RESTful an toàn cho bảng điều khiển web tương tác với các dịch vụ backend. Amazon DynamoDB: Cung cấp lưu trữ NoSQL nhanh chóng cho cấu hình phòng, trạng thái thiết bị và nhật ký cảm biến lịch sử. Amazon EventBridge: Điều phối các quy trình làm việc theo sự kiện, chẳng hạn như cập nhật cấu hình theo lịch trình hoặc kiểm tra nhịp tim (heartbeat). Amazon SNS: Gửi thông báo email cho quản trị viên liên quan đến cảnh báo hệ thống hoặc cập nhật quan trọng. Amazon S3: Lưu trữ các tài sản tĩnh frontend (HTML, CSS, JS) cho Bảng điều khiển Quản lý. Amazon CloudFront: Phân phối ứng dụng web toàn cầu với độ trễ thấp và bảo mật SSL. Amazon Cognito: Quản lý danh tính người dùng, xác thực và kiểm soát truy cập cho Bảng điều khiển Quản lý. Amazon CloudWatch: Thu thập nhật ký và số liệu để giám sát sức khỏe hệ thống và gỡ lỗi thực thi Lambda. Thiết kế thành phần Sensor Hubs: Each IoT-enabled room device collects environmental data (temperature, humidity, light, etc.) and sends it to AWS IoT Core every two minutes. Sensor Hubs: Các thiết bị hỗ trợ IoT (ESP32) trong mỗi phòng thu thập dữ liệu từ xa (nhiệt độ, độ ẩm, ánh sáng) và truyền đến AWS IoT Core vài phút một lần. Data Ingestion (Tiếp nhận dữ liệu): Các quy tắc AWS IoT Core kích hoạt HandleTelemetry Lambda, chức năng này xác thực dữ liệu và lưu vào Amazon DynamoDB. Configuration Management (Quản lý cấu hình): Quản trị viên sử dụng bảng điều khiển để cập nhật cài đặt phòng. RoomConfigHandler Lambda cập nhật DynamoDB và đẩy các thay đổi xuống thiết bị qua IoT Core Shadows hoặc MQTT. User Interaction (Tương tác người dùng): Bảng điều khiển Web (trên S3/CloudFront) trực quan hóa dữ liệu thời gian thực và cung cấp giao diện điều khiển. User Authentication (Xác thực người dùng): Amazon Cognito đảm bảo chỉ các thành viên phòng lab được ủy quyền mới có thể đăng nhập và truy cập dữ liệu phòng nhạy cảm. Monitoring \u0026amp; Reliability (Giám sát \u0026amp; Độ tin cậy): Amazon CloudWatch theo dõi hiệu suất hệ thống, đảm bảo tính sẵn sàng cao và khắc phục sự cố nhanh chóng. 4. Triển khai kỹ thuật Giai đoạn triển khai Nghiên cứu \u0026amp; Nền tảng (Tuần 1-7): Nghiên cứu các dịch vụ AWS cốt lõi (IoT Core, Lambda, DynamoDB, S3, API Gateway, Cognito) và hiểu các mô hình thiết kế Serverless. Thiết kế Kiến trúc \u0026amp; Dự toán (Tuần 8): Hoàn thiện sơ đồ giải pháp cho thiết lập 8 phòng và sử dụng AWS Pricing Calculator để dự báo ngân sách. Phát triển (Tuần 9-12): Triển khai firmware/kịch bản mô phỏng dữ liệu IoT. Phát triển Backend: Các hàm Lambda, bảng DynamoDB và tài nguyên API Gateway sử dụng CloudFormation/CDK. Phát triển Frontend: Xây dựng Bảng điều khiển Quản lý và tích hợp với các API. Kiểm thử \u0026amp; Triển khai (Tuần 13): Thực hiện kiểm thử toàn diện (end-to-end), xác thực luồng dữ liệu từ cảm biến đến bảng điều khiển và triển khai hệ thống lên môi trường production. Yêu cầu kỹ thuật Tầng Phần cứng: Các Sensor Hub dựa trên ESP32 giám sát các chỉ số môi trường. Tầng Đám mây: Một stack hoàn toàn serverless trên AWS (IoT Core, Lambda, DynamoDB, API Gateway, S3, CloudFront, Cognito, EventBridge, SNS). DevOps: Cơ sở hạ tầng dưới dạng Mã (IaC) sử dụng AWS CloudFormation để triển khai có thể tái lập. Giao diện: Bảng điều khiển web tương thích (responsive) cho phép giám sát thời gian thực và cập nhật cấu hình. 5. Lộ trình \u0026amp; Mốc triển khai Lộ trình Tuần 1–7: Tìm hiểu sâu về các dịch vụ AWS và hoàn thành khóa đào tạo cơ bản \u0026ldquo;First Cloud AI Journey\u0026rdquo;. Tuần 8: Thiết kế kiến trúc hệ thống và hoàn thiện dự toán chi phí. Tuần 9–12: Giai đoạn phát triển cốt lõi (Logic Backend, Lược đồ Database, Tích hợp giao diện Frontend). Tuần 13: Kiểm thử tích hợp hệ thống, gỡ lỗi và trình bày Go-Live cuối cùng. 6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator\nHoặc tải tệp ước tính ngân sách.\nChi phí hạ tầng Dịch vụ AWS:\nAmazon DynamoDB: Miễn phí (Gói Always Free: 25GB Lưu trữ). AWS Lambda: Miễn phí (Gói Always Free: 1 triệu yêu cầu/tháng). AWS IoT Core: $0.18/tháng (8 thiết bị, gửi dữ liệu mỗi 2 phút). Amazon API Gateway: Miễn phí (Gói Free Tier: 1 triệu cuộc gọi/tháng trong 12 tháng). Amazon S3: Miễn phí (Lưu trữ Standard \u0026lt; 5GB). Amazon CloudFront: $1.27/tháng (Dựa trên ước tính truyền dữ liệu và yêu cầu). Amazon EventBridge: Miễn phí (Sự kiện trong gói Free Tier). Amazon SNS: $0.02/tháng (Thông báo qua Email). Amazon CloudWatch: $0.25/tháng (Thu thập và lưu trữ log). Amazon Cognito: Miễn phí (Gói Free Tier: 50,000 MAUs). Phần cứng: Giả lập script Tổng cộng: ≈ $1.81/tháng, hoặc $21.72/năm (được tối ưu hóa trong giới hạn AWS Free Tier).\n7. Đánh giá rủi ro Ma trận rủi ro Vấn đề Kết nối IoT: Tác động trung bình, xác suất trung bình. Dữ liệu Cảm biến Không chính xác: Tác động trung bình, xác suất thấp. Phí AWS Ngoài dự kiến: Tác động thấp, xác suất thấp (do cảnh báo ngân sách chặt chẽ). Cấu hình Bảo mật Sai: Tác động cao, xác suất thấp. Chiến lược giảm thiểu Kết nối: Triển khai logic thử lại (retry) trên thiết bị biên và lưu đệm cục bộ. Chi phí: Cấu hình AWS Budgets để cảnh báo khi chi tiêu vượt quá $5.00. Bảo mật: Thực thi các chính sách IAM nghiêm ngặt (Đặc quyền Tối thiểu) và yêu cầu xác thực cho tất cả truy cập API qua Cognito. Độ tin cậy: Sử dụng CloudWatch Logs để truy vết lỗi trong thực thi Lambda ngay lập tức. Kế hoạch dự phòng Kích hoạt các điều khiển ghi đè thủ công nếu hệ thống đám mây không khả dụng. Duy trì bản sao lưu của các mẫu CloudFormation để triển khai lại nhanh chóng. 8. Kết quả kỳ vọng Cải tiến kỹ thuật: Thay thế việc kiểm tra thủ công bằng giám sát kỹ thuật số thời gian thực. Cung cấp một nền tảng tập trung để quản lý cấu hình trên nhiều phòng. Thiết lập một kiến trúc có khả năng mở rộng để hỗ trợ nhiều thiết bị hơn trong tương lai. Giá trị dài hạn: Phục vụ như một trung tâm học tập thực tế cho sinh viên để làm chủ các công nghệ AWS Serverless. Cung cấp thông tin chi tiết về dữ liệu có thể dẫn đến các chính sách sử dụng năng lượng tốt hơn trong phòng lab. Chứng minh một giải pháp đám mây hiệu quả về chi phí, sẵn sàng cho sản xuất. Proposal Link Smart_Office_Proposal\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.2-prerequiste/","title":"Các bước chuẩn bị","tags":[],"description":"","content":"Tạo IAM User cho workshop này Trong AWS Management Console, tìm kiếm và chọn IAM Điều hướng đến User, nhấp vào Create user Tại mục User name, nhập admin-user Tích chọn Provide user access to the AWS Management Console - optional Tại mục Console password, chọn Custom password Nhập mật khẩu cho user của bạn Bỏ chọn Users must create a new password at next sign-in - Recommended để thao tác dễ dàng hơn Nhấp Next Tại mục Permissions options, chọn Attach policies directly Nhấp Create policy Bạn sẽ được điều hướng đến trang Create policy Tại mục Policy editor, chuyển sang JSON Sao chép và dán đoạn policy này vào { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;InfrastructureManagement\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudformation:*\u0026#34;, \u0026#34;iam:*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;BackendComputeAndAPI\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;lambda:*\u0026#34;, \u0026#34;apigateway:*\u0026#34;, \u0026#34;execute-api:*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;DatabaseAndAuth\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:*\u0026#34;, \u0026#34;cognito-idp:*\u0026#34;, \u0026#34;cognito-identity:*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;IoTServices\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;iot:*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;StorageAndHosting\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:*\u0026#34;, \u0026#34;cloudfront:*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;MonitoringAndLogging\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;events:*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Nhấp Next Tại mục Policy name, nhập tên policy của bạn (Ví dụ: SmartOfficeAdminFullAcccess) Thêm Tags để quản lý chi phí và vận hành (Key: Project, Value: SmartOffice; Key: Environment, Value: Dev) Nhấp Create policy Quay lại Step 2 Set permissions của phần Create user Tìm kiếm và chọn tên policy của bạn Nhấp Next Thêm Tags để quản lý chi phí và vận hành (Key: Project, Value: SmartOffice; Key: Environment, Value: Dev) Nhấp Create user Đăng nhập bằng tài khoản User của bạn để bắt đầu workshop này "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.2-event2/","title":"Sự kiện 2","tags":[],"description":"","content":"Báo cáo tóm tắt: \u0026ldquo;AWS Cloud Mastery Series #2: DevOps trên AWS\u0026rdquo; Mục tiêu sự kiện Tư duy DevOps (DevOps Mindset) Dịch vụ AWS DevOps: Tập trung vào Quy trình CI/CD Cơ sở hạ tầng dưới dạng mã (IaC): Khái niệm và Công cụ Dịch vụ Container trên AWS Giám sát \u0026amp; Khả năng quan sát (Monitoring \u0026amp; Observability) Các phương pháp tối ưu (Best Practices) \u0026amp; Case Studies về DevOps Diễn giả Trương Quang Tính Nghiêm Lê Long Huỳnh Quý Phạm Điểm nhấn chính Tư duy DevOps Giá trị cốt lõi: Hợp tác, chia sẻ trách nhiệm và phá bỏ rào cản giữa các team. Tự động hóa: Mục tiêu là \u0026ldquo;tự động hóa mọi thứ\u0026rdquo;. Văn hóa: Học tập liên tục, thử nghiệm và đo lường dựa trên dữ liệu. Hành trình DevOps Nên làm (Do): Bắt đầu từ những kiến thức nền tảng. Học thông qua việc xây dựng các dự án thực tế. Tài liệu hóa mọi thứ bạn làm. Làm chủ từng công cụ/khái niệm một. Nâng cao kỹ năng mềm (giao tiếp/hợp tác). Không nên làm (Don\u0026rsquo;t): Sa đà vào \u0026ldquo;bẫy hướng dẫn\u0026rdquo; (học lý thuyết suông mà không thực hành). Copy-paste code một cách mù quáng mà không hiểu. So sánh tiến độ của bản thân với người khác. Bỏ cuộc sau những thất bại ban đầu. Quy trình CI/CD Vòng đời: Hiểu trọn vẹn vòng đời ứng dụng từ viết code, kiểm thử, review code, đến môi trường pre-prod và môi trường production thực tế. Cơ sở hạ tầng dưới dạng mã (IaC) Khái niệm: Quản lý tài nguyên đám mây bằng code thay vì thao tác thủ công trên giao diện. Lợi ích: Tự động tạo, cập nhật và xóa cơ sở hạ tầng một cách nhất quán. Công cụ: Terraform, OpenTofu, Pulumi. Dịch vụ Container trên AWS Hệ sinh thái: Quản lý container bằng Docker, Kubernetes, Amazon ECR và Amazon EKS. Amazon App Runner: Dịch vụ AWS nhanh chóng, đơn giản và tối ưu chi phí để triển khai ứng dụng web trực tiếp từ source code hoặc container image mà không cần quản lý máy chủ hay cấu hình hạ tầng. Giám sát \u0026amp; Khả năng quan sát Áp dụng các phương pháp tối ưu (best practices) với Amazon CloudWatch và Amazon X-Ray để đảm bảo sức khỏe hệ thống và khả năng truy vết. Bài học chính (Key Takeaways) Các chỉ số DevOps Mục đích: Giám sát sức khỏe của việc triển khai (deployment), cải thiện sự linh hoạt, đảm bảo tính ổn định của hệ thống, tối ưu hóa trải nghiệm khách hàng và chứng minh hiệu quả đầu tư công nghệ. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.3-blog3/","title":"Giao thức mở cho khả năng tương tác của Agent, Phần 3: Strands Agents &amp; MCP","tags":[],"description":"","content":"Giao thức mở cho khả năng tương tác của Agent, Phần 3: Strands Agents \u0026amp; MCP Bởi Nick Aldridge, James Ward, và Clare Liguori | 10 THÁNG 7 NĂM 2025\nDanh mục: Trí tuệ Nhân tạo, Giải pháp Khách hàng, Mã nguồn Mở\nGiới thiệu Các nhà phát triển đang kiến trúc và xây dựng các hệ thống gồm các AI agent có khả năng làm việc cùng nhau để tự động hoàn thành nhiệm vụ của người dùng. Trong Phần 1 của loạt bài blog về Giao thức mở cho khả năng tương tác của Agent, chúng tôi đã đề cập đến cách Giao thức Ngữ cảnh Mô hình (MCP) có thể được sử dụng để tạo điều kiện giao tiếp giữa các agent và các cải tiến đặc tả MCP mà AWS đang thực hiện để hiện thực hóa điều đó. Các ví dụ trong Phần 1 đã sử dụng Spring AI và Java để xây dựng các agent và kết nối chúng với MCP. Trong Phần 2 chúng tôi đã thảo luận về Xác thực trên MCP. Đây là một khía cạnh quan trọng của việc kết nối các agent để chúng có thể làm việc cùng nhau trong một hệ thống lớn hơn, tất cả đều có kiến thức về người dùng là ai.\nTrong Phần 3, chúng tôi sẽ trình bày cách bạn có thể xây dựng các hệ thống liên agent với Strands Agents SDK mới và MCP.\nStrands Agents là một SDK mã nguồn mở áp dụng phương pháp tiếp cận dựa trên mô hình để xây dựng và chạy các AI agent chỉ với vài dòng mã Python. Bạn có thể đọc thêm về Strands Agents trong tài liệu. Vì Strands Agents hỗ trợ MCP, chúng ta có thể nhanh chóng xây dựng một hệ thống bao gồm nhiều agent kết nối với nhau và sau đó triển khai các agent đó trên AWS.\nVí dụ của chúng ta là một agent Nhân sự (HR agent) có thể trả lời các câu hỏi về nhân viên. Để làm được điều này, bạn có thể hình dung agent Nhân sự sẽ giao tiếp với một số agent khác như agent dữ liệu nhân viên, agent Hoạch định Nguồn lực Doanh nghiệp (ERP), agent hiệu suất, agent mục tiêu, v.v. Đối với ví dụ này, hãy bắt đầu với một kiến trúc cơ bản trong đó một REST API cung cấp quyền truy cập vào một agent Nhân sự, agent này sẽ kết nối với agent thông tin nhân viên:\nKiến trúc ví dụ HR Agent\nLưu ý: Phiên bản đầy đủ và có thể chạy được của ví dụ dưới đây có sẵn trong repo mẫu Agentic AI.\nTạo Hệ Thống Các Agent với Strands Agents và MCP Hãy bắt đầu với MCP server sẽ cung cấp dữ liệu nhân viên để sử dụng trong agent thông tin nhân viên. Đây là một MCP server cơ bản:\nfrom mcp.server.fastmcp import FastMCP mcp = FastMCP(\u0026#34;employee-server\u0026#34;, stateless_http=True, host=\u0026#34;0.0.0.0\u0026#34;, port=8002) @mcp.tool() def get_skills() -\u0026gt; set[str]: \u0026#34;\u0026#34;\u0026#34;all of the skills that employees may have - use this list to figure out related skills\u0026#34;\u0026#34;\u0026#34; return SKILLS @mcp.tool() def get_employees_with_skill(skill: str) -\u0026gt; list[dict]: \u0026#34;\u0026#34;\u0026#34;employees that have a specified skill - output includes fullname (First Last) and their skills\u0026#34;\u0026#34;\u0026#34; skill_lower = skill.lower() return [employee for employee in EMPLOYEES if any(s.lower() == skill_lower for s in employee[\u0026#34;skills\u0026#34;])] if __name__ == \u0026#34;__main__\u0026#34;: mcp.run(transport=\u0026#34;streamable-http\u0026#34;) MCP server này cung cấp khả năng lấy danh sách kỹ năng nhân viên và lấy danh sách các nhân viên có kỹ năng cụ thể. Đối với ví dụ này, chúng tôi đang sử dụng dữ liệu giả định và trong blog tương lai, chúng tôi sẽ chia sẻ cách bảo mật dịch vụ này.\nBây giờ chúng ta đã có cách để agent lấy thông tin nhân viên này, hãy tạo employee agent sử dụng Strands Agents. Agent của chúng ta kết nối với MCP server để lấy thông tin nhân viên và sử dụng Bedrock để suy luận. Chúng ta cũng thêm một system prompt để cung cấp thêm một số hành vi cho agent này:\nEMPLOYEE_INFO_URL = os.environ.get(\u0026#34;EMPLOYEE_INFO_URL\u0026#34;, \u0026#34;http://localhost:8002/mcp/\u0026#34;) employee_mcp_client = MCPClient(lambda: streamablehttp_client(EMPLOYEE_INFO_URL)) bedrock_model = BedrockModel( model_id=\u0026#34;amazon.nova-micro-v1:0\u0026#34;, region_name=\u0026#34;us-east-1\u0026#34;, ) def employee_agent(question: str): with employee_mcp_client: tools = employee_mcp_client.list_tools_sync() agent = Agent(model=bedrock_model, tools=tools, system_prompt=\u0026#34;you must abbreviate employee first names and list all their skills\u0026#34;, callback_handler=None) return agent(question) Ví dụ này sử dụng Amazon Bedrock và mô hình Nova Micro với công cụ dữ liệu nhân viên để suy luận đa lượt. Suy luận đa lượt là khi một AI agent thực hiện nhiều lần gọi đến một mô hình AI trong một vòng lặp, thường liên quan đến việc gọi các công cụ để lấy hoặc cập nhật dữ liệu, hoàn thành khi nhiệm vụ ban đầu được thực hiện hoặc xảy ra lỗi. Trong ví dụ này, suy luận đa lượt cho phép một luồng như:\nNgười dùng hỏi \u0026ldquo;liệt kê các nhân viên có kỹ năng liên quan đến AI\u0026rdquo; LLM thấy rằng nó có quyền truy cập vào danh sách kỹ năng nhân viên và chỉ dẫn agent gọi công cụ đó Agent gọi công cụ get_skills của nhân viên và trả về các kỹ năng cho LLM LLM sau đó xác định kỹ năng nào liên quan đến AI và thấy rằng nó có thể lấy nhân viên với mỗi kỹ năng bằng cách sử dụng công cụ get_employees_with_skill Agent lấy nhân viên cho mỗi kỹ năng và trả chúng lại cho LLM LLM sau đó tập hợp danh sách đầy đủ các nhân viên có kỹ năng liên quan đến AI và trả về Tương tác đa lượt này qua nhiều lần gọi LLM và nhiều lần gọi công cụ được đóng gói thành một lần gọi agent(question) duy nhất, cho thấy sức mạnh của Strands Agents thực hiện một vòng lặp agentic để đạt được nhiệm vụ được cung cấp. Ví dụ này cũng cho thấy cách employee agent có thể thêm các chỉ dẫn bổ sung trên các công cụ cơ bản, trong trường hợp này với một system prompt.\nCông khai một Agent dưới dạng MCP Server Chúng ta có thể tương tác với agent này theo nhiều cách. Ví dụ, chúng ta có thể công khai nó như một dịch vụ REST. Trong trường hợp của chúng ta, chúng ta muốn công khai nó theo cách cho phép các agent khác tương tác với nó. Chúng ta có thể sử dụng MCP để tạo điều kiện giao tiếp giữa các agent đó bằng cách công khai agent này dưới dạng một MCP server. Sau đó, một agent khác (ví dụ: HR agent) sẽ có thể sử dụng employee agent như một công cụ.\nĐể công khai employee agent dưới dạng một MCP server, chúng ta chỉ cần bọc hàm employee_agent của chúng ta trong một @mcp.tool, chuyển đổi dữ liệu phản hồi thành một danh sách các chuỗi và khởi động server:\nmcp = FastMCP(\u0026#34;employee-agent\u0026#34;, stateless_http=True, host=\u0026#34;0.0.0.0\u0026#34;, port=8001) @mcp.tool() def inquire(question: str) -\u0026gt; list[str]: \u0026#34;\u0026#34;\u0026#34;answers questions related to our employees\u0026#34;\u0026#34;\u0026#34; return [ content[\u0026#34;text\u0026#34;] for content in employee_agent(question).message[\u0026#34;content\u0026#34;] if \u0026#34;text\u0026#34; in content ] if __name__ == \u0026#34;__main__\u0026#34;: mcp.run(transport=\u0026#34;streamable-http\u0026#34;) Vì chúng ta đã bọc employee agent trong một MCP server, bây giờ chúng ta có thể sử dụng nó trong các agent khác. HR agent được công khai dưới dạng một REST API để chúng ta có thể gọi nó từ một ứng dụng web hoặc các dịch vụ khác.\nEMPLOYEE_AGENT_URL = os.environ.get(\u0026#34;EMPLOYEE_AGENT_URL\u0026#34;, \u0026#34;http://localhost:8001/mcp/\u0026#34;) hr_mcp_client = MCPClient(lambda: streamablehttp_client(EMPLOYEE_AGENT_URL)) bedrock_model = BedrockModel( model_id=\u0026#34;amazon.nova-micro-v1:0\u0026#34;, region_name=\u0026#34;us-east-1\u0026#34;, temperature=0.9, ) app = FastAPI(title=\u0026#34;HR Agent API\u0026#34;) class QuestionRequest(BaseModel): question: str @app.get(\u0026#34;/health\u0026#34;) def health_check(): return {\u0026#34;status\u0026#34;: \u0026#34;healthy\u0026#34;} @app.post(\u0026#34;/inquire\u0026#34;) async def ask_agent(request: QuestionRequest): async def generate(): with hr_mcp_client: tools = hr_mcp_client.list_tools_sync() agent = Agent(model=bedrock_model, tools=tools, callback_handler=None) async for event in agent.stream_async(request.question): if \u0026#34;data\u0026#34; in event: yield event[\u0026#34;data\u0026#34;] return StreamingResponse( generate(), media_type=\u0026#34;text/plain\u0026#34; ) if __name__ == \u0026#34;__main__\u0026#34;: uvicorn.run(app, host=\u0026#34;0.0.0.0\u0026#34;, port=8000) Triển khai MCP và Strands Agents trên AWS Tất nhiên, chúng ta có thể chạy tất cả những điều này trên AWS bằng cách sử dụng nhiều tùy chọn khác nhau. Vì các MCP server sử dụng phương thức vận chuyển MCP Streamable HTTP mới, điều này có thể được chạy trên các runtime serverless như AWS Lambda hoặc AWS Fargate. Đối với ví dụ này, chúng tôi sẽ đóng gói employee info MCP server, employee agent và HR agent vào container, chạy chúng trên ECS và công khai HR agent thông qua một load balancer:\nMCP và Strands Agents trên Cơ sở Hạ tầng AWS\nĐối với ví dụ này, chúng tôi đã sử dụng AWS CloudFormation để định nghĩa cơ sở hạ tầng (nguồn). Bây giờ với mọi thứ đang chạy trên AWS, chúng ta có thể thực hiện một yêu cầu đến HR agent:\ncurl -X POST --location \u0026#34;http://something.us-east-1.elb.amazonaws.com/inquire\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;question\u0026#34;: \u0026#34;list employees that have skills related to AI programming\u0026#34;}\u0026#39; Và chúng ta nhận được:\nHere are the employees with skills related to AI programming: 1. W. Rodriguez - Machine Learning, REST API 2. M. Rodriguez - DevOps, Machine Learning, Python 3. R. Rodriguez - Machine Learning, JavaScript 4. J. Rodriguez - REST API, Kubernetes, Machine Learning, Node.js 5. W. Garcia - AWS, Kubernetes, GraphQL, Machine Learning 6. W. Davis - MongoDB, Angular, Kotlin, Machine Learning, REST API 7. J. Miller - React, Machine Learning, SQL, Kotlin 8. J. Rodriguez - SQL, Machine Learning, Docker, DevOps, Git If you need more detailed information about any of these employees or require further assistance, please let me know! Lấy mã nguồn đầy đủ cho ví dụ này.\nĐóng góp của AWS cho Khả năng Tương tác Tác nhân AI Ví dụ này chỉ cho thấy phần bắt đầu của những gì chúng ta có thể làm với Strands Agents và MCP để giao tiếp giữa các agent. Chúng tôi đã làm việc với đặc tả MCP và các triển khai để giúp phát triển MCP nhằm hỗ trợ các khả năng bổ sung mà một số trường hợp sử dụng liên agent có thể cần.\nĐặc tả MCP vừa có một phiên bản mới 2025-06-18 bao gồm hai đóng góp từ AWS để hỗ trợ tốt hơn cho giao tiếp giữa các agent. Chúng tôi cũng đã đóng góp hỗ trợ cho các tính năng mới này trong nhiều triển khai MCP khác nhau.\n1. Elicitation (Khai thác) Elicitation: Khi các MCP server cần đầu vào bổ sung, chúng có thể báo hiệu điều đó cho agent (thông qua MCP client). Thay vì một lần gọi công cụ cung cấp phản hồi dữ liệu, nó có thể khai thác thông tin bổ sung. Ví dụ, nếu một Employee Info Agent sử dụng công cụ MCP để lấy dữ liệu nhân viên xác định rằng một yêu cầu công cụ như \u0026ldquo;lấy nhân viên có kỹ năng AI\u0026rdquo; có thể trả về nhiều kết quả hơn người dùng mong muốn, nó có thể khai thác rằng người dùng cung cấp tên nhóm để lọc. Cách tiếp cận này khác với một tham số công cụ vì các đặc điểm runtime có thể xác định rằng tên nhóm là cần thiết.\nTrong một bài blog tương lai trong loạt bài này, chúng tôi sẽ đi sâu hơn vào cách sử dụng tính năng này. Chúng tôi đã đóng góp các triển khai của thay đổi đặc tả này cho các MCP SDK Java và Python, cả hai đều đã hợp nhất các thay đổi:\nThay đổi Java SDK Thay đổi Python SDK 2. Structured Output Schemas (Lược đồ Đầu ra có Cấu trúc) Structured Output Schemas: Các công cụ MCP thường trả về dữ liệu cho agent (thông qua MCP client) nhưng ngược lại với các lược đồ đầu vào (luôn được yêu cầu), chúng tôi đã đóng góp một cách để các công cụ tùy chọn chỉ định một lược đồ đầu ra. Điều này cho phép các agent thực hiện chuyển đổi an toàn hơn về kiểu dữ liệu của đầu ra công cụ thành dữ liệu có kiểu, cho phép các chuyển đổi an toàn và dễ dàng hơn của dữ liệu đó trong agent.\nChúng tôi cũng sẽ đề cập đến tính năng này nhiều hơn trong các bài blog tương lai trong loạt bài này. Các triển khai của tính năng này đã được đóng góp cho các MCP SDK Java, Python và TypeScript với triển khai TypeScript đã được hợp nhất:\nPull request Java SDK Pull request Python SDK Pull request TypeScript SDK Kết luận Thật thú vị khi thấy tiến bộ với MCP cho giao tiếp giữa các agent và trong các phần tương lai của loạt bài này, chúng tôi sẽ đi sâu hơn vào cách các cải tiến này có thể được sử dụng để cho phép các tương tác phong phú hơn giữa các agent.\nTrong blog này, chúng ta đã thấy cách chúng ta có thể sử dụng Strands Agents và MCP để tạo một hệ thống các agent tất cả làm việc cùng nhau và chạy trên AWS. Strands Agents đã giúp dễ dàng xây dựng một agent kết nối với các công cụ MCP, và sau đó cũng công khai agent như một MCP server để các agent khác có thể giao tiếp với nó. Để bắt đầu tìm hiểu về Strands Agents, hãy xem tài liệu và repo GitHub. Hãy theo dõi để biết thêm các phần của loạt bài này về Khả năng Tương tác Agent!\nVề các Tác giả Nick Aldridge Nick Aldridge là một Principal Engineer tại AWS. Trong 6 năm qua, Nick đã làm việc trên nhiều sáng kiến AI/ML bao gồm Amazon Lex và Amazon Bedrock. Gần đây nhất, anh ấy đã lãnh đạo nhóm ra mắt Amazon Bedrock Knowledge Bases. Ngày nay, anh ấy làm việc trên AI tổng quát và cơ sở hạ tầng AI với trọng tâm vào sự cộng tác giữa các agent và gọi hàm. Trước AWS, Nick đã có bằng MS tại Đại học Chicago.\nJames Ward James Ward là một Principal Developer Advocate tại AWS. James đi khắp thế giới giúp các nhà phát triển doanh nghiệp học cách xây dựng các hệ thống đáng tin cậy. Trọng tâm hiện tại của anh ấy là giúp các nhà phát triển xây dựng các hệ thống AI agent sử dụng Spring AI, Embabel, Strands Agents, Amazon Bedrock, MCP và A2A.\nClare Liguori Clare Liguori là một Senior Principal Software Engineer cho AWS Agentic AI. Cô ấy tập trung vào việc tái tưởng tượng cách các ứng dụng được xây dựng và các nhà phát triển có thể hiệu quả như thế nào khi các công cụ của họ được hỗ trợ bởi AI tổng quát và AI agent, như một phần của Amazon Q Developer.\nTài nguyên Open Source tại AWS Các Dự án trên GitHub Tài liệu Strands Agents Kho lưu trữ GitHub Strands Agents Model Context Protocol (MCP) AWS Samples - Bản demo Agentic AI Tags: Trí tuệ Nhân tạo, Mã nguồn Mở, Model Context Protocol, Strands Agents, Amazon Bedrock, Hệ thống Đa Agent\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":"Tại đây sẽ là phần liệt kê, giới thiệu các blogs mà các bạn đã dịch:\nBlog 1 - Đại học California Irvine Sao lưu Petabyte Dữ liệu Nghiên cứu lên AWS Bài viết này trình bày giải pháp sao lưu dữ liệu nghiên cứu quy mô lớn của Đại học California Irvine. Bạn sẽ tìm hiểu cách sao lưu 10 PB dữ liệu được phân tán trên 1500 phòng lab bằng cách sử dụng rclone, AWS S3, và các dịch vụ liên quan. Bài viết bao gồm kiến trúc hệ thống, tối ưu hóa hiệu suất, kiểm soát chi phí, và các chiến lược giám sát bằng CloudWatch.\nBlog 2 - Hướng dẫn Khởi động IP và Miền Tên và Di chuyển đến Amazon SES Bài viết này cung cấp những thực tiễn tốt nhất để khởi động địa chỉ IP và tên miền khi di chuyển tới Amazon SES. Bạn sẽ hiểu tầm quan trọng của quá trình khởi động IP, các thách thức thường gặp, và chiến lược hiệu quả cho từng nhà cung cấp email (Gmail, Hotmail, Outlook, Yahoo, iCloud, AOL). Bài viết bao gồm lịch trình khởi động 40 ngày chi tiết và các mẹo duy trì tính toàn vẹn người gửi.\nBlog 3 - Giao thức Mở cho Khả năng Tương tác Tác nhân Phần 3: Strands Agents \u0026amp; MCP Bài viết kỹ thuật này khám phá cách xây dựng các hệ thống đa tác nhân sử dụng Strands Agents và Model Context Protocol. Bạn sẽ tìm hiểu kiến trúc tác nhân, mẫu giao tiếp, tích hợp MCP, và cách triển khai trên AWS ECS với Amazon Bedrock. Bài viết bao gồm các ví dụ mã Python, các mô hình tương tác tác nhân, và những thách thức kỹ thuật.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.3-week3/","title":"Worklog Tuần 3","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 3: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 3: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.3-run-cloudformation-stack/","title":"Thiết lập CloudFormation","tags":[],"description":"","content":"Tải xuống tài nguyên Tải xuống các tệp mẫu CloudFormation này:\nsmart_office_budget.yaml smart_office_s3_cloudfront.yaml smart_office_cognito.yaml smart_office_dynamodb.yaml smart_office_lambda_authenticate_with_dynamodb_cognito.yaml smart_office_lambda_readonly_with_dynamodb.yaml smart_office_lambda_crud_with_dynamodb_cognito.yaml smart_office_lambda_crud_with_dynamodb_iot.yaml smart_office_iot_core.yaml smart_office_api_gateway.yaml Triển khai các CloudFormation Stack Trong AWS Management Console, tìm kiếm và chọn CloudFormation Nhấp vào Create stack Tại mục Prepare template, tích chọn Choose an existing template Tại mục Template source, tích chọn Upload a template file Nhấp vào Choose file Chọn tệp smart_office_budget.yaml Nhấp vào Next Tại mục Stack name, nhập SmartOffice-Budget-Dev Nhấp vào Next Thêm Tags để quản lý chi phí và vận hành (Key: Project, Value: SmartOffice; Key: Environment, Value: Dev) Tại mục Stack failure options, tích chọn Preserve successfully provisioned resources (Để giữ lại tài nguyên đã tạo phục vụ việc gỡ lỗi) Nhấp vào Next Kiểm tra lại và nhấp vào Submit Thực hiện tương tự cho các tệp khác với tên chính xác như sau Tên Template Tên Stack smart_office_s3_cloudfront.yaml SmartOffice-S3-CloudFront-Dev smart_office_cognito.yaml SmartOffice-Cognito-Dev smart_office_dynamodb.yaml SmartOffice-DynamoDB-Dev smart_office_lambda_authenticate_with_dynamodb_cognito.yaml SmartOffice-Authenticate-Lambda-Dev smart_office_lambda_readonly_with_dynamodb.yaml SmartOffice-ReadOnly-Lambda-Dev smart_office_lambda_crud_with_dynamodb_cognito.yaml SmartOffice-Crud-Lambda-Dev smart_office_lambda_crud_with_dynamodb_iot.yaml SmartOffice-IoT-Lambda-Dev smart_office_iot_core.yaml SmartOffice-IoT-Core-Dev smart_office_api_gateway.yaml SmartOffice-API-Gateway-Dev "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":"Event 1 Tên sự kiện: AWS Cloud Mastery Series #1: AI/ML/GenAI on AWS\nThời gian: 8:30 ngày 15/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nMô tả ngắn gọn: Giới thiệu về các Mô hình Nền tảng (Foundation Models) và khả năng của Generative AI sử dụng Amazon Bedrock. Buổi chia sẻ tập trung vào các kỹ thuật prompting hiệu quả (Chain of Thought) và kiến trúc RAG (Retrieval-Augmented Generation) để tích hợp cơ sở tri thức nội bộ. Khám phá chi tiết về vector embeddings với Amazon Titan và tổng quan về các dịch vụ AI khác nhau của AWS.\nKết quả: Có được kiến thức toàn diện về việc giảm thiểu ảo giác AI và nâng cao độ chính xác của phản hồi thông qua RAG và Embeddings. Học cách áp dụng các dịch vụ AI cụ thể của AWS và chiến lược prompting vào các dự án thực tế. Sự kiện cung cấp những hiểu biết giá trị về việc xây dựng AI agent và cơ hội kết nối với các diễn giả có chuyên môn.\nEvent 2 Tên sự kiện: AWS Cloud Mastery Series #2: ​DevOps on AWS\nThời gian: 8:30 ngày 17/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nMô tả ngắn gọn: Tổng quan toàn diện về tư duy DevOps, nhấn mạnh vào sự hợp tác, tự động hóa và chia sẻ trách nhiệm. Buổi chia sẻ bao gồm các dịch vụ AWS DevOps thiết yếu như quy trình CI/CD, Cơ sở hạ tầng dưới dạng mã (IaC) với CloudFormation và Terraform, cùng quản lý container sử dụng Amazon EKS và AppRunner. Hướng dẫn về những điều \u0026ldquo;Nên và Không nên\u0026rdquo; trong hành trình DevOps cùng các phương pháp giám sát tối ưu.\nKết quả: Có được lộ trình rõ ràng cho sự nghiệp DevOps và hiểu sâu hơn về vòng đời ứng dụng. Học cách triển khai quy trình CI/CD và sử dụng các mẫu IaC để giảm thiểu lỗi do con người. Có được cái nhìn sâu sắc về việc giám sát tình trạng triển khai và độ ổn định hệ thống thông qua các trường hợp thực tế và demo từ chuyên gia.\nEvent 3 Tên sự kiện: AWS Cloud Mastery Series #3: ​Theo AWS Well-Architected Security Pillar\nThời gian: 8:30 ngày 29/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nMô tả ngắn gọn: Đi sâu vào Trụ cột Bảo mật (Security Pillar) của AWS Well-Architected, bao gồm Quản lý Danh tính \u0026amp; Truy cập (IAM), Bảo vệ Cơ sở hạ tầng và Bảo vệ Dữ liệu. Buổi chia sẻ khám phá các biện pháp bảo mật nền tảng như Chính sách Kiểm soát Dịch vụ (SCPs), Ranh giới Phân quyền và MFA. Nêu bật các chiến lược nâng cao về \u0026ldquo;Phát hiện như Mã nguồn\u0026rdquo; (Detection-as-Code) bằng công cụ IaC và quy trình ứng phó sự cố tự động với Amazon EventBridge.\nKết quả: Học cách thực thi nguyên tắc đặc quyền tối thiểu một cách hiệu quả bằng SCP và ranh giới IAM. Có được kỹ năng thực tế trong việc thiết lập cảnh báo tự động và định tuyến sự kiện liên tài khoản để phát hiện mối đe dọa theo thời gian thực. Hiểu rõ quy trình ứng phó sự cố, nhấn mạnh vào phòng ngừa và tự động hóa để giảm thiểu thời gian ngừng hoạt động và rủi ro bảo mật.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.2-event3/","title":"Sự kiện 4","tags":[],"description":"","content":"Báo cáo tóm tắt: \u0026ldquo;AWS Cloud Mastery Series #3: Trụ cột Bảo mật trong AWS Well-Architected\u0026rdquo; Mục tiêu sự kiện Nền tảng Bảo mật (Security Foundation) Quản lý Định danh \u0026amp; Truy cập (IAM) Phát hiện \u0026amp; Giám sát Bảo vệ Cơ sở hạ tầng Bảo vệ Dữ liệu Ứng phó Sự cố (Incident Response) Diễn giả Lê Vũ Xuân An Trần Đức Anh Trần Đoàn Công Lý Danh Hoàng Hiếu Nghị Thịnh Lâm Việt Nguyễn Mendel Branski (Long) Điểm nhấn chính Giới thiệu về Cloud Club Giới thiệu các CLB Điện toán đám mây tại các trường đại học như UTE, SGU. Các hoạt động cộng đồng của Cloud Club. Nền tảng Bảo mật Chính sách kiểm soát dịch vụ (Service Control Policies - SCP). Ranh giới quyền hạn (Permission Boundaries). Xác thực đa yếu tố (MFA). Phát hiện và Giám sát Khả năng hiển thị bảo mật đa lớp (Multi-Layer Security Visibility). Cảnh báo \u0026amp; Tự động hóa với Amazon EventBridge. Detection-as-Code (Phát hiện rủi ro bằng mã). Bảo vệ Mạng và Dữ liệu Chia sẻ VPC Security Group. Bảo mật cho các dịch vụ dựa trên API. Quản lý bí mật (Secret Management). Ứng phó sự cố Phòng ngừa: Tại sao không ai có đủ thời gian để xử lý sự cố thủ công. Sức khỏe tinh thần: Hướng dẫn \u0026ldquo;ngủ ngon hơn\u0026rdquo; bằng cách giảm thiểu mệt mỏi vì cảnh báo (alert fatigue). Quy trình: Xây dựng quy trình ứng phó sự cố chuẩn. Bài học chính (Key Takeaways) Service Control Policies (SCPs) Định nghĩa: Một loại chính sách cấp Tổ chức (Organization). Chức năng: Kiểm soát các quyền hạn tối đa có sẵn cho tất cả các tài khoản trong tổ chức. Nguyên tắc: SCP không bao giờ cấp quyền; chúng chỉ có thể lọc hoặc giới hạn quyền. Permission Boundaries (Ranh giới quyền hạn) Mục đích: Tính năng IAM nâng cao được thiết kế để giải quyết vấn đề ủy quyền. Chức năng: Đặt ra quyền hạn tối đa mà một chính sách dựa trên định danh (identity-based policy) có thể cấp cho một User hoặc Role cụ thể. Xác thực đa yếu tố (MFA) TOTP: Dựa trên bí mật chia sẻ, yêu cầu nhập mã 6 chữ số thủ công (ví dụ: Google Authenticator). Miễn phí, sao lưu và khôi phục linh hoạt. FIDO2: Sử dụng mật mã khóa công khai, yêu cầu quét sinh trắc học hoặc chạm đơn giản (ví dụ: YubiKey). Bảo mật cao nhưng yêu cầu quy trình sao lưu nghiêm ngặt. Cảnh báo \u0026amp; Tự động hóa với EventBridge Sự kiện thời gian thực: Các sự kiện CloudTrail được chuyển đến EventBridge để xử lý ngay lập tức. Cảnh báo tự động: Phát hiện các hoạt động đáng ngờ trên tất cả các tài khoản của tổ chức. Định tuyến sự kiện liên tài khoản (Cross-account): Xử lý sự kiện tập trung và phản hồi tự động. Tích hợp \u0026amp; Quy trình: Tích hợp với SNS, Slack và SQS để phản hồi bảo mật tự động và thông báo cho đội ngũ. Detection-as-Code Triển khai IaC: Triển khai GuardDuty trên toàn tổ chức bằng CloudFormation/Terraform (bật gói bảo vệ, cấu hình nguồn dữ liệu). Quy tắc phát hiện tùy chỉnh: Xây dựng các quy tắc loại trừ (suppression rules) \u0026amp; danh sách trắng IP để giảm dương tính giả (false positives). Logic được kiểm soát phiên bản: Theo dõi các quy tắc phát hiện trong Git và tích hợp vào quy trình DevSecOps để kiểm thử và triển khai. Ứng phó sự cố Chuẩn bị: Chuẩn bị sẵn các trình xử lý tự động (automation handlers) cho sự cố. Dự đoán: Dự đoán các sự cố tương lai và thiết kế kế hoạch ứng phó. Hậu sự cố: Rút ra \u0026ldquo;Bài học kinh nghiệm\u0026rdquo; (Lessons Learned) sau mỗi sự cố. Áp dụng vào công việc Đặc quyền tối thiểu: Quy định và thực thi chính sách đặc quyền tối thiểu (least privilege) cho dự án. Bắt buộc MFA: Áp dụng MFA cho mọi tài khoản (Root và IAM user). Lập kế hoạch: Dự đoán và chuẩn bị sẵn sàng cho các sự cố trong tương lai. Trải nghiệm sự kiện Tham dự hội thảo “AWS Well-Architected Security Pillar” đã giúp tôi cải thiện đáng kể kiến thức về bảo mật và ứng phó sự cố thông qua việc trải nghiệm các Trụ cột Bảo mật AWS, bao gồm:\nHọc hỏi từ các diễn giả có chuyên môn cao Học cách các Senior Engineer xử lý khi sự cố xảy ra và quy trình rút kinh nghiệm sau đó. Học cách bảo vệ dữ liệu và mạng lưới với các tính năng bảo mật của AWS. Khám phá hoạt động Cloud Club Làm quen với các hoạt động của Cloud Club giúp kết nối cộng đồng người học AWS từ khắp mọi nơi. Cảnh báo \u0026amp; Tự động hóa Có khả năng chuẩn bị cơ sở hạ tầng như CloudTrail, EventBridge, CloudWatch để quản lý tài nguyên trong thời gian thực ngay khi sự cố phát sinh. Tổng kết: Sự kiện là cơ hội để tôi mở rộng kiến thức về Cảnh báo, Tự động hóa, Bảo mật và Ứng phó sự cố. Tôi đã tích lũy được nhiều kinh nghiệm thông qua việc lắng nghe các Senior Cloud Engineer chia sẻ về công việc thực tế của họ.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-set-up-website/","title":"Thiết lập website","tags":[],"description":"","content":"Thiết lập Gitlab repository để triển khai website và lambda code Truy cập Gitlab repository này: https://gitlab.com/tranngockhiet22062005/smart-office Tải xuống và triển khai trên repository của riêng bạn Thiết lập role cho Gitlab để triển khai website lên S3 và triển khai code lên Lambda Function Tạo một IAM User với các thuộc tính sau (xem lại phần 5.2 nếu bạn quên) User name: smart-office-gitlab-ci Policy: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;S3ListBucketAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:GetBucketLocation\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::fcj-smart-office-frontend-ACCOUNT_ID-dev\u0026#34;, \u0026#34;arn:aws:s3:::fcj-smart-office-lambda-ACCOUNT_ID-dev\u0026#34; ] }, { \u0026#34;Sid\u0026#34;: \u0026#34;S3ReadWriteAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:PutObjectAcl\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::fcj-smart-office-frontend-ACCOUNT_ID-dev/*\u0026#34;, \u0026#34;arn:aws:s3:::fcj-smart-office-lambda-ACCOUNT_ID-dev/*\u0026#34; ] }, { \u0026#34;Sid\u0026#34;: \u0026#34;LambdaUpdateAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;lambda:UpdateFunctionCode\u0026#34;, \u0026#34;lambda:GetFunction\u0026#34;, \u0026#34;lambda:GetFunctionConfiguration\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:lambda:*:*:function:SmartOffice-*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;CloudFrontInvalidation\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudfront:CreateInvalidation\u0026#34;, \u0026#34;cloudfront:GetDistribution\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Bạn nên thay thế ACCOUNT_ID bằng AWS Account ID của bạn Policy name: SmartOfficeGitlabAccess Điều hướng đến user đó Trong phần Summary, nhấp vào Create access key Tại mục Use case, tích chọn Command Line Interface (CLI) Tích chọn I understand the above recommendation and want to proceed to create an access key. Nhấp Next Nhấp Create access key Nhấp Download .csv file Cấu hình các biến Gitlab Truy cập Gitlab repository của bạn, nhấp vào Setting \u0026gt; Variables Nhấp Add variable Đối với mỗi Key và Value, hãy làm theo bảng dưới đây để biết nơi lấy giá trị\nKey Value AWS_ACCESS_KEY_ID In your smart-office-gitlab-ci_accessKeys.csv you have downloaded AWS_DEFAULT_REGION ap-southeast-1 (or anywhere you deploy the workshop) AWS_SECRET_ACCESS_KEY In your smart-office-gitlab-ci_accessKeys.csv you have downloaded CLOUDFRONT_DISTRIBUTION_ID CloudFront \u0026gt; Distributions \u0026gt; Your distribution ID S3_BUCKET_FRONTEND fcj-smart-office-frontend-ACCOUNT_ID-dev (replace ACCOUNT_ID with your AWS Account ID) S3_BUCKET_LAMBDA fcj-smart-office-lambda-ACCOUNT_ID-dev (replace ACCOUNT_ID with your AWS Account ID) STACK_NAME_AUTH SmartOffice-Authenticate-Lambda-Dev STACK_NAME_CRUD SmartOffice-Crud-Lambda-Dev STACK_NAME_IOT SmartOffice-IoT-Lambda-Dev STACK_NAME_READONLY SmartOffice-ReadOnly-Lambda-Dev VITE_API_BASE_URL API Gateway \u0026gt; SmartOffice-API-Gateway-Dev-Api \u0026gt; Stages \u0026gt; Invoke URL Push code vào nhánh init\nMerge các branch theo thứ tự sau: init -\u0026gt; dev, dev -\u0026gt; main\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.5-event-bridge/","title":"Thiết lập EventBridge và Lambda","tags":[],"description":"","content":"Tổng quan Phần này sẽ hướng dẫn bạn cách thiết lập Amazon EventBridge và Lambda để định tuyến và phản ứng với các sự kiện xảy ra trong DynamoDB. Để thiết lập SNS (được sử dụng để gửi cảnh báo), vui lòng tham khảo phần 5.6 - Thiết lập SNS.\nTạo AutomationSetup (Lambda + rules) Tạo một hàm Lambda (AutomationSetup) có nhiệm vụ đọc cấu hình tự động từ DynamoDB và xác định hai rule EventBridge: một để bật tự động hoá và một khác để tắt tự động hoá. import boto3 import json import os from boto3.dynamodb.types import TypeDeserializer deserializer = TypeDeserializer() events_client = boto3.client(\u0026#39;events\u0026#39;) HANDLER_ARN = os.environ.get(\u0026#39;HANDLER_LAMBDA_ARN\u0026#39;) def ddb_deserialize(image): d = {} for key in image: d[key] = deserializer.deserialize(image[key]) return d def time_to_cron(time_str): try: hour, minute = map(int, time_str.split(\u0026#39;:\u0026#39;)) utc_hour = hour - 7 if utc_hour \u0026lt; 0: utc_hour += 24 return f\u0026#34;cron({minute} {utc_hour} * * ? *)\u0026#34; except: return None # --- CẬP NHẬT 1: Thêm tham số office_id vào hàm --- def create_or_update_schedule(room_id, office_id, time_str, action): rule_name = f\u0026#34;Room_{room_id}_Auto_{action}\u0026#34; cron_expr = time_to_cron(time_str) if not cron_expr: return print(f\u0026#34;Updating Rule: {rule_name} with Input\u0026#34;) events_client.put_rule( Name=rule_name, ScheduleExpression=cron_expr, State=\u0026#39;ENABLED\u0026#39;, Description=f\u0026#39;Auto {action} for {room_id} in {office_id}\u0026#39; ) # --- CẬP NHẬT 2: Thêm officeId vào JSON Input --- target_input = json.dumps({ \u0026#34;roomId\u0026#34;: room_id, \u0026#34;officeId\u0026#34;: office_id, # \u0026lt;--- QUAN TRỌNG: Bao gồm officeId \u0026#34;command\u0026#34;: action.upper(), \u0026#34;source\u0026#34;: \u0026#34;Scheduled_Event\u0026#34; }) events_client.put_targets( Rule=rule_name, Targets=[{ \u0026#39;Id\u0026#39;: \u0026#39;1\u0026#39;, \u0026#39;Arn\u0026#39;: HANDLER_ARN, \u0026#39;Input\u0026#39;: target_input }] ) def lambda_handler(event, context): print(\u0026#34;Raw Event:\u0026#34;, json.dumps(event)) if \u0026#39;Records\u0026#39; in event: for record in event[\u0026#39;Records\u0026#39;]: if record[\u0026#39;eventName\u0026#39;] in [\u0026#39;INSERT\u0026#39;, \u0026#39;MODIFY\u0026#39;]: raw_image = record[\u0026#39;dynamodb\u0026#39;][\u0026#39;NewImage\u0026#39;] data = ddb_deserialize(raw_image) room_id = data.get(\u0026#39;roomId\u0026#39;) # --- CẬP NHẬT 3: Lấy officeId từ DynamoDB --- office_id = data.get(\u0026#39;officeId\u0026#39;) auto_control = data.get(\u0026#39;autoControl\u0026#39;) auto_on = data.get(\u0026#39;autoOnTime\u0026#39;) auto_off = data.get(\u0026#39;autoOffTime\u0026#39;) if auto_control == \u0026#34;ON\u0026#34; and room_id: # Chuyển office_id tới hàm tạo lịch biểu if auto_on: create_or_update_schedule(room_id, office_id, auto_on, \u0026#39;ON\u0026#39;) if auto_off: create_or_update_schedule(room_id, office_id, auto_off, \u0026#39;OFF\u0026#39;) return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: \u0026#39;Processed\u0026#39;} Đi tới Configuration \u0026ndash;\u0026gt; Trigger để cấu hình các trigger Lambda — điều này sẽ được sử dụng để gọi lambda bất cứ khi nào có luồng mới từ DynamoDB Chọn Add Trigger, chọn DynamoDB và chọn bảng chứa cấu hình phòng. Trong Configuration \u0026ndash;\u0026gt; Environment Variable, thêm cặp khóa-giá trị này (thay thế tương ứng bằng thông tin cá nhân của bạn) Chọn Configuration \u0026ndash;\u0026gt;Role name, và đảm bảo bạn có 3 chính sách này: AutomationSetup_RuleExecuiton để tạo rule trong EventBridge AWSLambdaBasicExecutionRole cho quyền thực thi lambda cơ bản AWSLambdaDynamoDBExecutionRole để tương tác với DynamoDB. { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;events:DeleteRule\u0026#34;, \u0026#34;events:PutTargets\u0026#34;, \u0026#34;events:EnableRule\u0026#34;, \u0026#34;events:PutRule\u0026#34;, \u0026#34;events:DisableRule\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Chỉ dành cho AutomationSetup_RuleExecuiton, chọn Add permissions \u0026ndash;\u0026gt; Create inline policy\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:ap-southeast-1:261899902491:*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:logs:ap-southeast-1:261899902491:log-group:/aws/lambda/AutomationSetup:*\u0026#34; ] } ] } AWSLambdaBasicExecutionRole\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:DescribeStream\u0026#34;, \u0026#34;dynamodb:GetRecords\u0026#34;, \u0026#34;dynamodb:GetShardIterator\u0026#34;, \u0026#34;dynamodb:ListStreams\u0026#34;, \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } AWSLambdaDynamoDBExecutionRole\nHai rule này tương ứng với hành vi tự động hoá BẬT và TẮT.\nTạo AutomationHandler (Lambda để chuyển tiếp các sự kiện tới AWS IoT Core) Tạo Lambda AutomationHandler để nhận các sự kiện từ EventBridge và chuyển tiếp chúng tới AWS IoT Core. import boto3 import json import logging logger = logging.getLogger() logger.setLevel(logging.INFO) iot_client = boto3.client(\u0026#39;iot-data\u0026#39;, region_name=\u0026#39;ap-southeast-1\u0026#39;) def lambda_handler(event, context): \u0026#34;\u0026#34;\u0026#34; Đầu vào từ EventBridge: {\u0026#34;roomId\u0026#34;: \u0026#34;test2\u0026#34;, \u0026#34;officeId\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;ON\u0026#34;, ...} \u0026#34;\u0026#34;\u0026#34; # Ghi nhật ký toàn bộ sự kiện để xác minh tải trọng logger.info(f\u0026#34;Executing Automation: {json.dumps(event)}\u0026#34;) # 1. Trích xuất dữ liệu từ Sự kiện room_id = event.get(\u0026#39;roomId\u0026#39;) command = event.get(\u0026#39;command\u0026#39;) # BẬT / TẮT office_id = event.get(\u0026#39;officeId\u0026#39;) # 2. Xác thực dữ liệu đầu vào if not room_id or not command: logger.error(\u0026#34;Missing roomId or command\u0026#34;) return {\u0026#39;statusCode\u0026#39;: 400, \u0026#39;body\u0026#39;: \u0026#39;Missing roomId or command\u0026#39;} if not office_id: logger.error(\u0026#34;Missing officeId\u0026#34;) return {\u0026#39;statusCode\u0026#39;: 400, \u0026#39;body\u0026#39;: \u0026#39;Missing officeId\u0026#39;} # 3. Tạo Chủ đề và Tải trọng topic = f\u0026#34;office/{office_id}/room/{room_id}/config\u0026#34; payload = { \u0026#34;command\u0026#34;: \u0026#34;SET_STATE\u0026#34;, \u0026#34;value\u0026#34;: command, \u0026#34;triggeredBy\u0026#34;: \u0026#34;Schedule\u0026#34; } # 4. Gửi lệnh tới IoT Core try: # Dòng này phải được căn chỉnh với các dòng ở trên response = iot_client.publish( topic=topic, qos=1, payload=json.dumps(payload) ) logger.info(f\u0026#34;SUCCESS: Sent {command} to {topic}\u0026#34;) return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: \u0026#39;Command sent\u0026#39;} except Exception as e: logger.error(f\u0026#34;IoT Publish Error: {e}\u0026#34;) # Nâng cao lỗi để EventBridge biết nó không thành công (kích hoạt Retry/DLQ) raise e Đi tới Configuration \u0026ndash;\u0026gt; Permissions và thêm resource-based policy. (Để cho phép EventBridge truy cập hàm lambda này) Thêm rule được tạo bởi AutomationSetup làm kích hoạt cho Lambda này. Thay thế REGION, ACCOUNT, ARNs và tên tài nguyên bằng các giá trị từ tài khoản của bạn trước khi chạy.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Smart Office Management System Workshop Tổng quan (Overview) Smart Office Management System cung cấp giải pháp giám sát và quản lý môi trường thời gian thực cho văn phòng, được xây dựng hoàn toàn trên nền tảng AWS Serverless giúp tối ưu hóa chi phí và khả năng mở rộng.\nTrong bài lab này, bạn sẽ học cách triển khai, cấu hình và kiểm thử một hệ thống IoT full-stack, cho phép các thiết bị cảm biến gửi dữ liệu lên đám mây và người quản trị có thể điều khiển thiết bị thông qua Web Dashboard.\nBạn sẽ làm việc với hai mô hình kiến trúc chính để vận hành hệ thống Smart Office:\nServerless Architecture - Sử dụng AWS Lambda, API Gateway, và DynamoDB để xử lý logic và lưu trữ dữ liệu. Mô hình này cho phép mã chạy để phản hồi các yêu cầu mà không cần quản lý máy chủ. Event-Driven Architecture - Sử dụng AWS IoT Core, EventBridge, và SNS. Hệ thống hoạt động dựa trên sự kiện, nơi dữ liệu từ cảm biến hoặc hành động của người dùng sẽ kích hoạt các quy trình tự động hóa và gửi thông báo cảnh báo. Nội dung (Content) Giới thiệu Các bước chuẩn bị Thiết lập CloudFormation Thiết lập website Thiết lập EventBridge và Lambda Thiết lập SNS Kiểm thử kết nối giữa website và thiết bị IoT "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong suốt thời gian thực tập tại [Tên công ty/tổ chức] từ [ngày bắt đầu] đến [ngày kết thúc], tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia [mô tả ngắn gọn dự án hoặc công việc chính], qua đó cải thiện kỹ năng [liệt kê kỹ năng: lập trình, phân tích, viết báo cáo, giao tiếp…].\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ☐ ✅ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.6-sns/","title":"Thiết lập SNS","tags":[],"description":"","content":"Tổng quan Phần này sẽ hướng dẫn bạn cách thiết lập Amazon SNS (Dịch vụ Thông báo Đơn giản) để nhận cảnh báo từ EventBridge khi phát hiện bất thường dữ liệu.\nTạo Topic SNS Đi tới Bảng điều khiển Amazon SNS Chọn Topic và đặt tên cho Topic của bạn KHÔNG BẬT MÃ HÓA\nTạo Subscription SNS Sau khi tạo chủ đề, hãy tạo một hoặc nhiều đăng ký để cảnh báo được gửi đến người nhận hoặc điểm cuối (trong trường hợp này, email).\nCác bước:\nChọn Subscription trong SNS Chọn giao thức email, chọn topic bạn vừa tạo và ghi lại email bạn muốn kiểm tra. Các điểm cuối email yêu cầu xác nhận trước khi nhận các tin nhắn. Kiểm tra hộp thư của bạn để tìm email xác nhận từ AWS SNS và xác nhận đăng ký.\nTạo một rule và gắn nó vào topic SNS Đi tới Bảng điều khiển Amazon EventBridge Chọn Rules và tạo một rule mới Ở bước 2, chúng tôi xác định mẫu sự kiện bằng cách chọn Custom pattern. Các mẫu sự kiện có thể khớp với source, detail-type.\nSử dụng Json sau:\n{ \u0026#34;source\u0026#34;: [\u0026#34;com.smartoffice.iot\u0026#34;], \u0026#34;detail-type\u0026#34;: [\u0026#34;sensor.anomaly\u0026#34;] } Ở bước 3, chọn mục tiêu cho quy tắc — chọn topic SNS bạn đã tạo trước đó. Sau khi tạo, EventBridge sẽ chuyển tiếp các sự kiện phù hợp đến topic SNS sẽ chuyển đến các đăng ký của nó.\nThay thế địa chỉ email và tên tài nguyên bằng các giá trị từ tài khoản của bạn trước khi chạy.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nĐánh giá chung 1. Môi trường làm việc\nFCJ xây dựng bầu không khí chào đón và hợp tác, nơi các thành viên sẵn sàng hỗ trợ giải quyết thách thức ngay cả ngoài giờ làm việc. Bố trí không gian làm việc thúc đẩy sự tập trung, mặc dù tôi tin rằng các sự kiện xã hội định kỳ hoặc các buổi team-building có thể tăng cường thêm mối liên kết giữa các thực tập sinh và nhân viên.\n2. Sự hỗ trợ của mentor / team admin\nMentor của tôi liên tục cung cấp hướng dẫn kỹ lưỡng, phân tích các khái niệm phức tạp khi tôi gặp khó khăn, và tích cực thúc đẩy văn hóa đặt câu hỏi. Đội ngũ quản trị đơn giản hóa các nhu cầu hậu cần và đảm bảo quyền truy cập vào các tài nguyên thiết yếu. Tôi đặc biệt đánh giá cao phong cách huấn luyện của mentor—khuyến khích tự giải quyết vấn đề trước khi can thiệp với giải pháp.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCác dự án được giao kết nối hiệu quả giữa lý thuyết lớp học và thực tiễn công nghiệp mới nổi. Tôi đã củng cố các khái niệm học thuật cốt lõi trong khi khám phá các công nghệ và phương pháp không được đề cập trong chương trình học, đạt được sự cân bằng giữa củng cố và mở rộng kho kiến thức kỹ thuật của mình.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nKỳ thực tập giúp tôi tiếp xúc với các nền tảng quản lý dự án, kỹ thuật hợp tác liên chức năng và chuẩn mực giao tiếp chuyên nghiệp. Những hiểu biết của mentor về lập kế hoạch quỹ đạo nghề nghiệp và sự đánh đổi trong thực tế đã vô cùng quý giá cho việc định hình mục tiêu dài hạn của tôi.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nSự tôn trọng lẫn nhau và mục đích chung xác định văn hóa tổ chức. Các thành viên duy trì tiêu chuẩn cao trong khi vẫn giữ được môi trường dễ tiếp cận. Trong các sprint quan trọng, đồng nghiệp phối hợp trên nhiều cấp độ để đáp ứng thời hạn, khiến tôi cảm thấy được hòa nhập thay vì bị gạt ra ngoài lề dù là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nFCJ cung cấp trợ cấp và điều chỉnh lịch trình khi cần thiết. Quyền truy cập vào các chương trình đào tạo nội bộ và các buổi chia sẻ kiến thức là một lợi ích đáng kể vượt xa các chương trình thực tập thông thường.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Có thêm nhiều mối quan hệ với những người hấp dẫn Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Thành thật mà nói, tôi không biết Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Khởi đầu rất tốt nếu bạn muốn trở thành Cloud Engineer, DevOps Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Thành thật mà nói, tôi không biết Bạn có muốn tiếp tục chương trình này trong tương lai? Tôi nghĩ là có Góp ý khác (tự do chia sẻ): "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.7-test-website-iot-connection/","title":"Kiểm thử kết nối giữa website và thiết bị IoT","tags":[],"description":"","content":"Tải kịch bản giả lập thiết bị IoT main.py\nThêm dữ liệu cho thiết bị giả ENDPOINT = \u0026#34;\u0026#34; CLIENT_ID = \u0026#34;\u0026#34; OFFICE_ID = \u0026#34;\u0026#34; ROOM_ID = \u0026#34;\u0026#34; PATH_TO_CERT = \u0026#34;\u0026#34; PATH_TO_KEY = \u0026#34;\u0026#34; PATH_TO_ROOT = \u0026#34;\u0026#34; Thuộc tính Giá trị ENDPOINT Trên trang manager CLIENT_ID ID của office của bạn OFFICE_ID Tên office của bạn ROOM_ID ID phòng của bạn PATH_TO_CERT Đường dẫn tải xuống chứng chỉ thiết bị của bạn khi bạn tạo phòng PATH_TO_KEY Đường dẫn tải xuống khóa riêng của thiết bị khi bạn tạo phòng PATH_TO_ROOT Đường dẫn tải xuống chứng chỉ gốc Amazon của bạn khi bạn tạo phòng Link video demo https://www.youtube.com/watch?v=k45jHjkKhuc\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10: Smart Office - Rules Engine &amp; Lưu trữ dữ liệu","tags":[],"description":"","content":" ⚠️ Lưu ý: Thông tin dưới đây chỉ mang tính chất tham khảo. Vui lòng không sao chép nguyên văn cho báo cáo của bạn.\nMục tiêu Tuần 10: Triển khai Logic Hướng sự kiện (Event-Driven): Sử dụng AWS IoT Rules Engine để lọc và điều hướng các tin nhắn MQTT đến mà không cần quản lý server. Lưu trữ dữ liệu bền vững (Persistence): Cấu hình tích hợp Amazon DynamoDB để lưu trữ lịch sử dữ liệu cảm biến (Nhiệt độ, Độ ẩm) phục vụ phân tích sau này. Cảnh báo tự động: Thiết lập Amazon SNS topic để gửi thông báo tức thì khi chỉ số cảm biến vượt quá ngưỡng quy định (ví dụ: Cháy/Nhiệt độ cao). Các công việc thực hiện trong tuần: Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Thiết kế Database (NoSQL): + Tạo bảng DynamoDB SmartOffice_Telemetry. + Partition Key: device_id (String). + Sort Key: timestamp (Number/Epoch). + Mục tiêu: Tối ưu hóa cho các truy vấn theo chuỗi thời gian. 10/11/2025 10/11/2025 Best Practices cho DynamoDB Time-Series 3 - Cấu hình IoT Rule (Lưu trữ): + Viết câu truy vấn SQL: SELECT * FROM 'smart-office/+/data'. + Thêm Action: Insert message vào bảng DynamoDB. + Tạo IAM Role cấp quyền cho IoT Core thực hiện PutItem. 11/11/2025 11/11/2025 Tạo AWS IoT Rule 4 - Cấu hình IoT Rule (Cảnh báo): + Tạo SNS Topic Office_Alerts và subscribe email. + Viết truy vấn SQL với Condition: SELECT * FROM 'smart-office/+/data' WHERE temperature \u0026gt; 30. + Thêm Action: Gửi tin nhắn đến SNS. 12/11/2025 12/11/2025 Tài liệu tham khảo SQL IoT 5 - Kiểm thử toàn trình (End-to-End Testing): + Chạy thiết bị giả lập (từ Tuần 9). + Gửi dữ liệu \u0026ldquo;Bình thường\u0026rdquo; -\u0026gt; Kiểm tra dữ liệu xuất hiện trong DynamoDB. + Gửi dữ liệu \u0026ldquo;Nhiệt độ cao\u0026rdquo; -\u0026gt; Kiểm tra DynamoDB VÀ nhận Email cảnh báo. 13/11/2025 13/11/2025 Tự kiểm chứng 6 - Xử lý lỗi (Error Handling): + Cấu hình Error Action cho các IoT Rules. + Điều hướng các tin nhắn bị lỗi (ví dụ: do DynamoDB throttling) sang S3 hoặc SQS để debug. 14/11/2025 14/11/2025 Xử lý lỗi IoT Rules Kết quả đạt được trong Tuần 10: Xây dựng Backend Serverless cho IoT:\nTận dụng AWS IoT Rules Engine để tách biệt lớp thiết bị (Device layer) khỏi lớp lưu trữ (Storage layer). Không sử dụng bất kỳ EC2 instance nào để xử lý dữ liệu, giảm chi phí vận hành xuống mức tối thiểu. Thiết lập lưu trữ dữ liệu:\nĐã điều hướng thành công dữ liệu telemetry vào Amazon DynamoDB. Kiểm chứng thiết kế schema (device_id + timestamp), đảm bảo dữ liệu được lưu trữ hiệu quả cho việc truy xuất dashboard sau này. Triển khai phát hiện bất thường thời gian thực:\nCấu hình logic điều kiện (WHERE temperature \u0026gt; 30) ngay tại lớp tiếp nhận dữ liệu. Xác nhận các cảnh báo quan trọng (SNS) được kích hoạt ngay lập tức, trong khi dữ liệu bình thường chỉ được log lại, giúp tối ưu hóa chi phí và giảm nhiễu. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11: Smart Office - Serverless API &amp; Trực quan hóa","tags":[],"description":"","content":" ⚠️ Lưu ý: Thông tin dưới đây chỉ mang tính chất tham khảo. Vui lòng không sao chép nguyên văn cho báo cáo của bạn.\nMục tiêu Tuần 11: Xây dựng Logic xử lý (Business Layer): Phát triển hàm AWS Lambda để truy xuất và định dạng dữ liệu lịch sử cảm biến từ DynamoDB. Công khai dữ liệu qua REST API: Cấu hình Amazon API Gateway để tạo một endpoint HTTP bảo mật cho ứng dụng. Mở rộng kiến thức Cloud: Tham gia sự kiện AWS Cloud Mastery Series #2 để hiểu sâu hơn về các mô hình kiến trúc nâng cao. Các công việc thực hiện trong tuần: Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Tham gia sự kiện AWS Cloud Mastery Series #2 + Chủ đề: Advanced Serverless Patterns / Resilience. + Bài học: Hiểu về khái niệm idempotency và cold starts trong Serverless. 17/11/2025 17/11/2025 Ghi chú từ sự kiện 3 - Phát triển Logic Backend (Lambda): + Tạo hàm Lambda (Node.js/Python). + Gắn IAM Role với quyền dynamodb:Scan hoặc dynamodb:Query. + Viết code để lấy 10 bản ghi mới nhất từ bảng SmartOffice_Telemetry. 18/11/2025 18/11/2025 Xây dựng Lambda function với DynamoDB 4 - Cấu hình API Gateway: + Tạo REST API. + Tạo Resource /data và Method GET. + Tích hợp Method với hàm Lambda (Proxy Integration). 19/11/2025 19/11/2025 Xây dựng REST API với Lambda proxy 5 - Bảo mật \u0026amp; CORS: + Bật CORS (Cross-Origin Resource Sharing) trên API Gateway để cho phép trình duyệt truy cập. + Deploy API ra môi trường (Stage: dev). + Test Invoke URL bằng Postman hoặc curl. 20/11/2025 20/11/2025 Bật CORS cho REST API 6 - Trực quan hóa (Frontend POC): + Cập nhật S3 Static Website (từ Tuần 4/7). + Thêm mã JavaScript fetch() gọi tới API Endpoint mới tạo. + Hiển thị nhiệt độ thời gian thực lên trang web. 21/11/2025 21/11/2025 Tự kiểm chứng Kết quả đạt được trong Tuần 11: Phát triển thành công Serverless Business Logic:\nĐã viết và triển khai hàm AWS Lambda đóng vai trò cầu nối giữa lớp lưu trữ (DynamoDB) và người dùng cuối. Áp dụng nguyên tắc IAM Least Privilege (Đặc quyền tối thiểu) bằng cách chỉ cấp quyền Read cho hàm Lambda trên đúng bảng dữ liệu cần thiết. Xây dựng giao diện REST an toàn:\nTriển khai Amazon API Gateway để public dữ liệu IoT qua giao thức HTTP(S) tiêu chuẩn. Cấu hình CORS, giải quyết vấn đề bảo mật trình duyệt phổ biến khi kết nối Frontend (S3) với Backend API. Học tập liên tục:\nTích cực tham gia AWS Cloud Mastery Series #2, thu nạp các kiến thức thực tiễn về mô hình cloud chuẩn công nghiệp để áp dụng ngay vào dự án Smart Office hiện tại. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.12-week12/","title":"Worklog Tuần 12","tags":[],"description":"","content":"Mục tiêu tuần 12: Chuẩn bị cho kỳ thi cuối kỳ môn Academic Writing của trường đại học Hoàn thiện việc triển khai và tài liệu dự án Smart Office IoT Ôn tập và thực hành kỹ năng viết học thuật cho kỳ thi Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Ôn tập kiến thức cơ bản về viết học thuật - Thực hành cấu trúc và tổ chức bài luận - Học cách phát triển thesis statement 25/11/2025 25/11/2025 Tài liệu môn Academic Writing 3 - Thực hành viết bài luận tranh luận - Ôn tập các phong cách trích dẫn và tham khảo - Học kỹ thuật phát triển đoạn văn 26/11/2025 26/11/2025 Sách giáo khoa Academic Writing 4 - Hoàn thiện code dự án Smart Office IoT - Hoàn thành các Lambda functions cho Rules Engine - Kiểm tra lưu trữ dữ liệu DynamoDB - Xác minh tất cả tích hợp IoT Core 27/11/2025 28/11/2025 Tài liệu dự án 5 - Xây dựng API serverless với API Gateway - Tạo dashboard CloudWatch để trực quan hóa - Kiểm tra quy trình dự án end-to-end - Lập tài liệu kiến trúc và triển khai 28/11/2025 29/11/2025 Tài liệu AWS 6 - Thực hành viết bài luận theo thời gian giới hạn - Ôn tập các chủ đề và đề bài luận phổ biến - Chuẩn bị cho định dạng thi cuối kỳ - Hoàn thành ôn tập cuối và thi thử 29/11/2025 29/11/2025 Hướng dẫn thi của trường đại học Kết quả đạt được tuần 12: Chuẩn bị kỹ lưỡng cho kỳ thi cuối kỳ Academic Writing\nÔn tập cấu trúc bài luận: phần mở bài, thân bài và kết luận Thực hành xây dựng thesis statement và phát triển lập luận Học các dạng bài luận: tranh luận, giải thích và phân tích Nắm vững các định dạng trích dẫn (APA, MLA) và giọng điệu học thuật Hoàn thành nhiều bài luận thực hành theo thời gian giới hạn Hoàn thiện triển khai dự án Smart Office IoT Core:\nHoàn thành các Lambda functions xử lý dữ liệu cảm biến IoT Cấu hình EventBridge rules cho các quy trình tự động Thiết lập bảng DynamoDB cho lưu trữ dữ liệu bền vững Tích hợp SNS cho thông báo cảnh báo Xây dựng các API Gateway endpoints để lấy dữ liệu Tạo dashboard CloudWatch để giám sát thời gian thực Chuẩn bị tài liệu dự án đầy đủ:\nSơ đồ kiến trúc hiển thị tất cả dịch vụ AWS và tương tác của chúng Hướng dẫn triển khai từng bước với CloudFormation templates Tài liệu API với các yêu cầu và phản hồi mẫu Kết quả kiểm tra chứng minh chức năng hệ thống Trình bày dự án cuối cùng:\nThể hiện quy trình làm việc end-to-end hoàn chỉnh Giải thích các quyết định kỹ thuật và lựa chọn dịch vụ AWS Nêu bật các thách thức gặp phải và giải pháp triển khai Trình diễn dashboard trực quan hóa và hệ thống cảnh báo Phản tư về kinh nghiệm thực tập:\nTích lũy kinh nghiệm thực hành với hơn 15 dịch vụ AWS Phát triển kỹ năng về kiến trúc serverless và giải pháp IoT Cải thiện hiểu biết về phương pháp hay nhất trên cloud và Well-Architected Framework Xây dựng dự án portfolio thể hiện triển khai AWS thực tế "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.13-week13/","title":"Worklog Tuần 13: Chứng chỉ AWS trên Coursera","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 13: Hoàn thành khóa học viết học thuật trên Coursera để cải thiện kỹ năng viết tài liệu kỹ thuật Nâng cao khả năng viết báo cáo rõ ràng, có cấu trúc và chuyên nghiệp Áp dụng kỹ thuật viết vào các bài nộp thực tập và nội dung kỹ thuật Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Đăng ký khóa học viết học thuật trên Coursera - Học module nền tảng viết - Tìm hiểu về cấu trúc, sự rõ ràng và nhận thức đối tượng 02/12/2025 02/12/2025 Khóa học Coursera Viết Học Thuật 3 - Hoàn thành module ngữ pháp và phong cách - Thực hành xây dựng câu và phát triển đoạn văn - Ôn tập các lỗi viết phổ biến và cách tránh 03/12/2025 03/12/2025 Khóa học Coursera Viết Học Thuật 4 - Học các nguyên tắc viết kỹ thuật - Tìm hiểu các phương pháp hay nhất về tài liệu - Thực hành viết mô tả kỹ thuật rõ ràng 04/12/2025 04/12/2025 Khóa học Coursera Viết Học Thuật 5 - Học phương pháp nghiên cứu và trích dẫn - Tìm hiểu cách cấu trúc lập luận và trình bày bằng chứng - Thực hành viết nội dung thuyết phục và cung cấp thông tin 05/12/2025 05/12/2025 Khóa học Coursera Viết Học Thuật 6 - Hoàn thành bài tập viết cuối cùng - Áp dụng kỹ thuật đã học vào báo cáo thực tập - Xem xét và sửa lại tài liệu hiện có 06/12/2025 06/12/2025 Khóa học Coursera Viết Học Thuật Kết quả đạt được tuần 13: Nâng cao kỹ năng viết học thuật:\nNắm vững các nguyên tắc cơ bản của viết học thuật rõ ràng và hiệu quả Phát triển kỹ năng ngữ pháp, dấu câu và cấu trúc câu mạnh mẽ hơn Học cách tổ chức ý tưởng một cách logic với chuyển tiếp và luồng phù hợp Cải thiện khả năng viết cho đối tượng và mục đích cụ thể Nâng cao kỹ năng viết tài liệu kỹ thuật áp dụng cho kỹ thuật đám mây Áp dụng kỹ thuật viết vào các bài nộp thực tập:\nSửa lại các mục worklog với sự rõ ràng và chuyên nghiệp được cải thiện Nâng cao mô tả kỹ thuật trong tài liệu dự án Cải thiện cấu trúc và sự mạch lạc của bản dịch workshop Tinh chỉnh tóm tắt blog với tổng hợp thông tin phức tạp tốt hơn Củng cố các câu chuyện tham gia sự kiện với bài học rõ ràng Phát triển thói quen viết chuyên nghiệp:\nLập kế hoạch cấu trúc nội dung trước khi viết Sử dụng giọng chủ động và ngôn ngữ súc tích Đọc lại và chỉnh sửa một cách có hệ thống Tìm kiếm phản hồi và lặp lại các bản nháp Duy trì giọng điệu và phong cách nhất quán trong suốt tài liệu Tăng tự tin trong giao tiếp bằng văn bản:\nKhả năng giải thích các khái niệm kỹ thuật rõ ràng cho đối tượng đa dạng Kỹ năng tạo ra các tài liệu chuyên nghiệp được đánh bóng, không có lỗi Hiểu biết về cách cấu trúc báo cáo, đề xuất và phân tích Năng lực trích dẫn nguồn và ghi nhận tài liệu tham khảo một cách phù hợp "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://thienluhoan.github.io/workshop-template/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]